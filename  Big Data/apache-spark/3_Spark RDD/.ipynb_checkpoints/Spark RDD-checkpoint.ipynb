{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark RDD\n",
    "\n",
    "- Internals of spark\n",
    "- What are the types of variables?\n",
    "\n",
    "## Spark Context\n",
    "- Main Entry point for Spark Functionality \n",
    "- Represents connection to a Spark Cluster\n",
    "- Current Status of Spark Application\n",
    "- Used to create\n",
    "    - RDD'd\n",
    "    - Accumulators\n",
    "    - Broadcast variables\n",
    "- Only one SparkContext may be active per JVM\n",
    "\n",
    "A Spark context contains:\n",
    "- RDD graph\n",
    "- DAGScheduler\n",
    "- Task scheduler\n",
    "- Scheduler backend\n",
    "- Listener bus\n",
    "- Block manager\n",
    "\n",
    "Spark Context Methods:\n",
    "\n",
    "- addFile, addJar, appName, applicationId, bradcast, isStopped...\n",
    "- deployMode, getConf, haddopFile, hadoppRDD, listFiles...\n",
    "\n",
    "## Accumulators\n",
    "Ex. Word count - If a spark application runs on multiple nodes at the same time, how a program running in node can know the count in a program running in another noder?\n",
    "\n",
    "- Shared Variable\n",
    "- Variables that are only \"added\" to through an associative and commutative operation and can therefore be efficiently supported in parallel\n",
    "- Used to implement Counters\n",
    "- Natively supports accumulators of numeric types\n",
    "\n",
    "## Broadcast Variables\n",
    "- Shared Variable\n",
    "- Allows developers to keep a read-only variable cached on all worker nodes\n",
    "\n",
    "## RDD\n",
    "Resilent Distributed Dataset\n",
    "- Read Only, partitioned collection of records\n",
    "- Immutable once constructed\n",
    "- Lineage\n",
    "- Rich set of Operations\n",
    "- Coarse-Grained Transformations \n",
    "\n",
    "- Can only be created through deterministic operations on \n",
    "    - Data\n",
    "    - Other RDD's\n",
    "- Persistence\n",
    "- Partitioning\n",
    "- Checkpointing\n",
    "\n",
    "### Create RDD\n",
    "\n",
    "```bash\n",
    "val data Array(1,2,3,4,5)\n",
    "val rdd = sc.parallelize(data)\n",
    "```\n",
    "Simple operations on rdd:\n",
    "\n",
    "```bash\n",
    "rdd.reduce((a,b)=>a+b) #Sum all elements\n",
    "rdd.getNumPartitions #Get number of partitions\n",
    "```\n",
    "\n",
    "## Operations\n",
    "\n",
    "Every RDD performs two sets of operations \n",
    "- Transformations\n",
    "    - A transformations is changing the form of the RDD from one stage to another stage (Creates a new dataset from an existing one)\n",
    "- Actions \n",
    "    - Materializing the transformations applied (returns a value to the driver program afetr running a computation on the dataset)\n",
    "\n",
    "## RDD Lineage\n",
    "Carrying forward the origin of data. There are two types of dependencies\n",
    "- Narrow Dependencies\n",
    "    - The child has a one to one relationship with its parent's partition\n",
    "- Wide Dependencies\n",
    "    - The child has a one to many relationship with its parent's partitions\n",
    "![RDD Lineage](https://programmersought.com/images/990/c3eef91f857f397ee62268325737fdce.png)\n",
    "\n",
    "Transformations are only computed after actions are called \n",
    "\n",
    "![Operations](https://blog.knoldus.com/wp-content/uploads/2019/10/Screenshot-from-2019-09-29-11-53-26.png)\n",
    "![Operations2](https://blog.knoldus.com/wp-content/uploads/2019/10/Screenshot-from-2019-09-29-11-53-31.png)\n",
    "\n",
    "## Transformations\n",
    "\n",
    "- map\n",
    "    - Return a new RDD by applying a function to each element of this RDD \n",
    "    - *takes a function as an argument, performs the operation and returns the new RDD by applying the function to each element of the RDD*)\n",
    "- flatMap\n",
    "    - Return a new RDD by first applying a function to all elements of this RDD, and then flattening the results \n",
    "    - *same as map, but flattens the results (takes the values out of the collection)\n",
    "- mapPartitions\n",
    "     - Return a new RDD by applying to each partition of the RDD\n",
    "     - same as map, but the function is applied to each partition of the RDD **instead of each element** of the RDD. \n",
    "- mapPartitionsWithIndex\n",
    "    - Return a new RDD by applying a function to each partition of the RDD (same as mapPartitions), while tracking the index of the original partition\n",
    "- getNumPartitions\n",
    "    - Return the number of partitions (available in the RDD)\n",
    "- filter(f)\n",
    "    - Return a new RDD containing only the elements that satisfy a condition\n",
    "- distinct(numPartitions=None)\n",
    "    - Return a new RDD containing the distinct elements in the current RDD \n",
    "- sample(withReplacement, fraction, seed=None)\n",
    "    - Return a sampled subset of this RDD.\n",
    "- groupBy(f, numPartitions=None, partitionFunc)\n",
    "    - Return an RDD of grouped items.\n",
    "    \n",
    "## Actions\n",
    "- foreach\n",
    "    - Applies a function to all elements of the current RDD\n",
    "- collect()\n",
    "    - Return a list thta contains all of the elements in the current RDD\n",
    "    - `This method should only be used if the resulting array is expected to be small, as all of the data is loaded into the driver's memory`\n",
    "- reduce(f)\n",
    "    - Reduces the elements of the RDD using the specified commutative and associative binary operator. Currently reduces partitions locally\n",
    "- max, min, count\n",
    "    - similar to SQL queries\n",
    "\n",
    "There are 2 types of actions:\n",
    "\n",
    "- Distributed\n",
    "    - Writing data to target system like HDFS localfile system or database\n",
    "- Driver \n",
    "    - sum, min, average, max \n",
    "    \n",
    "## Different types of RDD's\n",
    "\n",
    "![Types of RDD's](https://i.pinimg.com/originals/a8/ee/1d/a8ee1df6532cbb65aef1c3343405b820.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "nbTranslate": {
   "displayLangs": [
    "en",
    "es"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "es",
   "targetLang": "en",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "250.43478393554688px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
