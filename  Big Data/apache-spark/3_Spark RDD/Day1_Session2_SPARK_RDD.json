{"paragraphs":[{"text":"%md\n![SPARK](https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page2.svg)\n","dateUpdated":"2018-03-22T06:30:43+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><img src=\"https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page2.svg\" alt=\"SPARK\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681261_-1397966246","id":"20180321-000031_1359389925","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"focus":true,"$$hashKey":"object:15945"},{"text":"%md\n### Map\nReturn a new RDD by applying a function to each element of this RDD","dateUpdated":"2018-03-22T06:30:43+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>Map</h3>\n<p>Return a new RDD by applying a function to each element of this RDD</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681262_-1396811999","id":"20180320-232149_2050820537","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:15946"},{"text":"%md\n![SPARK](https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page3.svg)\n","dateUpdated":"2018-03-22T06:30:43+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><img src=\"https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page3.svg\" alt=\"SPARK\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681262_-1396811999","id":"20180321-000107_1195020770","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:15947"},{"text":"%spark\n//1\nval x = sc.parallelize(Array(2,4,6)) //Initialize an array of elements\nval y = x.map(x=> (x,x%2)) //Mapping each element with element and it's percentile 2\nx.collect() // gettng rdd x to driver\ny.collect() // getting rdd y to driver","dateUpdated":"2018-03-22T06:30:43+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"x: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[0] at parallelize at <console>:28\ny: org.apache.spark.rdd.RDD[(Int, Int)] = MapPartitionsRDD[1] at map at <console>:29\nres2: Array[Int] = Array(2, 4, 6)\nres3: Array[(Int, Int)] = Array((2,0), (4,0), (6,0))\n"}]},"apps":[],"jobName":"paragraph_1521699681262_-1396811999","id":"20180318-204350_1468153177","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:15948"},{"text":"\n%pyspark\n#1\nx = sc.parallelize([2,4,6]) \ny = x.map(lambda x: (x,x**3))\nprint(x.collect())  \nprint(y.collect())","dateUpdated":"2018-03-22T06:30:43+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"paragraph_1521686291207_1150055951's Interpreter %pyspar not found"}]},"apps":[],"jobName":"paragraph_1521699681262_-1396811999","id":"20180318-204452_1697433097","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:15949"},{"text":"%md\n### flatMap\nReturn a new RDD by first applying a function to all elements of this RDD, and then flattening the results.","dateUpdated":"2018-03-22T06:30:43+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>flatMap</h3>\n<p>Return a new RDD by first applying a function to all elements of this RDD, and then flattening the results.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681262_-1396811999","id":"20180320-232241_578911117","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:15950"},{"text":"%md\n![SPARK](https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page4.svg)","dateUpdated":"2018-03-22T06:30:44+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><img src=\"https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page4.svg\" alt=\"SPARK\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681262_-1396811999","id":"20180321-000119_1349906289","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:15951"},{"text":"%spark\n//2\nval x = sc.parallelize(List(\"demo data\",\"is shown\"), 2)\nval y = x.map(x => x.split(\" \")) \nval y = x.flatMap(x => x.split(\" \"))\ny.collect()\n","dateUpdated":"2018-03-22T06:30:44+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"x: org.apache.spark.rdd.RDD[String] = ParallelCollectionRDD[2] at parallelize at <console>:28\ny: org.apache.spark.rdd.RDD[Array[String]] = MapPartitionsRDD[3] at map at <console>:29\ny: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[4] at flatMap at <console>:29\nres5: Array[String] = Array(demo, data, is, shown)\n"}]},"apps":[],"jobName":"paragraph_1521699681262_-1396811999","id":"20180318-204957_1884937558","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:15952"},{"text":"%pyspark\n#2\nx = sc.parallelize([2,4,6])\ny = x.flatMap(lambda x: (x, 100*x, x**3))\nprint(x.collect())\nprint(y.collect())\n","dateUpdated":"2018-03-22T06:30:44+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[2, 4, 6]\n[2, 200, 8, 4, 400, 64, 6, 600, 216]\n"}]},"apps":[],"jobName":"paragraph_1521699681262_-1396811999","id":"20180318-205429_1881690604","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:15953"},{"text":"%md\n### mapPartitions\nReturn a new RDD by applying a function to each partition of this RDD","dateUpdated":"2018-03-22T06:30:44+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>mapPartitions</h3>\n<p>Return a new RDD by applying a function to each partition of this RDD</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681262_-1396811999","id":"20180320-232316_1732570918","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:15954"},{"text":"%md\n![SPARK](https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page5.svg)\n","dateUpdated":"2018-03-22T06:30:44+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><img src=\"https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page5.svg\" alt=\"SPARK\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681262_-1396811999","id":"20180321-000151_1919852168","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:15955"},{"text":"%spark\n//3\nval data = sc.parallelize(List(1,2,3,4,5,6,7,8), 2)\ndef sumfuncpartition(numbers : Iterator[Int]) : Iterator[Int] =\n{\nvar sum = 1\nwhile(numbers.hasNext)\n{\nsum = sum + numbers.next()\n}\nreturn Iterator(sum)\n}\ndata.glom.collect\ndata.mapPartitions(sumfuncpartition).collect\n ","dateUpdated":"2018-03-22T06:30:44+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"data: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[7] at parallelize at <console>:28\nsumfuncpartition: (numbers: Iterator[Int])Iterator[Int]\nres7: Array[Array[Int]] = Array(Array(1, 2, 3, 4), Array(5, 6, 7, 8))\nres8: Array[Int] = Array(11, 27)\n"}]},"apps":[],"jobName":"paragraph_1521699681262_-1396811999","id":"20180318-210248_1968533628","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:15956"},{"text":"%pyspark\n#3\nx = sc.parallelize([1,2,3], 2)\ndef f(iterator): yield sum(iterator)\ny = x.mapPartitions(f)\nprint(x.glom().collect())  \nprint(y.glom().collect())\n\n","dateUpdated":"2018-03-22T06:30:44+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[[1], [2, 3]]\n[[1], [5]]\n"}]},"apps":[],"jobName":"paragraph_1521699681262_-1396811999","id":"20180318-210256_1272181762","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:15957"},{"text":"%md\n### mapPartitionsWithIndex(f, preservesPartitioning=False)\nReturn a new RDD by applying a function to each partition of this RDD, while tracking the index of the original partition.","dateUpdated":"2018-03-22T06:30:45+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>mapPartitionsWithIndex(f, preservesPartitioning=False)</h3>\n<p>Return a new RDD by applying a function to each partition of this RDD, while tracking the index of the original partition.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681262_-1396811999","id":"20180320-232407_1347124130","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:15958"},{"text":"%md\n![SPARK](https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page6.svg)","dateUpdated":"2018-03-22T06:30:45+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><img src=\"https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page6.svg\" alt=\"SPARK\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681262_-1396811999","id":"20180321-000210_1580135535","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:15959"},{"text":"%spark\n//4\nval coloursrdd =  sc.parallelize(List(\"yellow\",\"red\",\"blue\",\"cyan\",\"black\"),3)\nval mappedrdd =   coloursrdd.mapPartitionsWithIndex{(index, iterator) =>  {val myList = iterator.toList\nmyList.map(x => x + \" -> \" + index).iterator}}\n\nmappedrdd.collect\n\n","dateUpdated":"2018-03-22T06:30:45+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true,"tableHide":true},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"coloursrdd: org.apache.spark.rdd.RDD[String] = ParallelCollectionRDD[13] at parallelize at <console>:28\nmappedrdd: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[17] at mapPartitionsWithIndex at <console>:31\n<console>:27: error: not found: value mapped\n       mapped.collect\n       ^\n"}]},"apps":[],"jobName":"paragraph_1521699681262_-1396811999","id":"20180318-210319_235951237","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:15960"},{"text":"%pyspark\n#4\nx = sc.parallelize([1,2,3], 2)\ndef f(partitionIndex, iterator): yield (partitionIndex,sum(iterator))\ny = x.mapPartitionsWithIndex(f)\nprint(x.glom().collect())  \nprint(y.glom().collect())\n\n","dateUpdated":"2018-03-22T06:30:45+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[[1], [2, 3]]\n[[(0, 1)], [(1, 5)]]\n"}]},"apps":[],"jobName":"paragraph_1521699681263_-1397196748","id":"20180318-211926_1598934868","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:15961"},{"text":"%md\n### getNumPartitions()\nreturns number of partitions","dateUpdated":"2018-03-22T06:30:45+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>getNumPartitions()</h3>\n<p>returns number of partitions</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681263_-1397196748","id":"20180320-232518_271002394","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:15962"},{"text":"%md\n![SPARK](https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page7.svg)\n","dateUpdated":"2018-03-22T06:30:45+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><img src=\"https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page7.svg\" alt=\"SPARK\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681263_-1397196748","id":"20180321-000222_640209950","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:15963"},{"text":"%spark\n//5\nval x = sc.parallelize(Array(1,2,3), 2)\nval y = x.getNumPartitions\nx.glom().collect()\nprintln(y)","dateUpdated":"2018-03-22T06:30:46+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"x: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[20] at parallelize at <console>:28\ny: Int = 2\nres13: Array[Array[Int]] = Array(Array(1), Array(2, 3))\n2\n"}]},"apps":[],"jobName":"paragraph_1521699681263_-1397196748","id":"20180318-212544_239063139","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:15964"},{"text":"%pyspark\n#5\nx = sc.parallelize([1,2,3], 2)\ny = x.getNumPartitions()\nprint(x.glom().collect())\nprint(y)\n","dateUpdated":"2018-03-22T06:30:46+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[[1], [2, 3]]\n2\n"}]},"apps":[],"jobName":"paragraph_1521699681263_-1397196748","id":"20180318-212551_682504209","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:15965"},{"text":"%md\n### filter(f)\nReturn a new RDD containing only the elements that satisfy a predicate\n","dateUpdated":"2018-03-22T06:30:46+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>filter(f)</h3>\n<p>Return a new RDD containing only the elements that satisfy a predicate</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681263_-1397196748","id":"20180320-232615_37758829","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:15966"},{"text":"%md\n![SPARK](https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page8.svg)\n","dateUpdated":"2018-03-22T06:30:46+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><img src=\"https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page8.svg\" alt=\"SPARK\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681263_-1397196748","id":"20180321-000233_723281249","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:15967"},{"text":"%spark\n//6\nval x = sc.parallelize(Array(1,2,3))\nval y = x.filter( x=> x%2 == 1) \nx.collect()\ny.collect()","dateUpdated":"2018-03-22T06:30:46+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"x: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[22] at parallelize at <console>:28\ny: org.apache.spark.rdd.RDD[Int] = MapPartitionsRDD[25] at filter at <console>:29\nres16: Array[Int] = Array(1, 2, 3)\nres17: Array[Int] = Array(1, 3)\n"}]},"apps":[],"jobName":"paragraph_1521699681263_-1397196748","id":"20180318-212817_640519683","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:15968"},{"text":"%pyspark\n#6\nx = sc.parallelize([1,2,3])\ny = x.filter(lambda x: x%2 == 1)  # filters out even elements\nprint(x.collect())\nprint(y.collect())\n\n","dateUpdated":"2018-03-22T06:30:46+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[1, 2, 3]\n[1, 3]\n"}]},"apps":[],"jobName":"paragraph_1521699681263_-1397196748","id":"20180318-212844_49155227","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:15969"},{"text":"%md\n### distinct(numPartitions=None)\nReturn a new RDD containing the distinct elements in this RDD\n","dateUpdated":"2018-03-22T06:30:47+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>distinct(numPartitions=None)</h3>\n<p>Return a new RDD containing the distinct elements in this RDD</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681263_-1397196748","id":"20180320-232641_681518437","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:15970"},{"text":"%md\n![SPARK](https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page9.svg)\n","dateUpdated":"2018-03-22T06:30:47+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><img src=\"https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page9.svg\" alt=\"SPARK\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681263_-1397196748","id":"20180321-000321_985091223","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:15971"},{"text":"%spark\n//7\nval x = sc.parallelize(Array('A','A','B'))\nval y = x.distinct()\nx.collect()\ny.collect()\n","dateUpdated":"2018-03-22T06:30:47+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"x: org.apache.spark.rdd.RDD[Char] = ParallelCollectionRDD[31] at parallelize at <console>:28\ny: org.apache.spark.rdd.RDD[Char] = MapPartitionsRDD[35] at distinct at <console>:29\nres19: Array[Char] = Array(A, A, B)\nres20: Array[Char] = Array(A, B)\n"}]},"apps":[],"jobName":"paragraph_1521699681263_-1397196748","id":"20180318-213021_332147808","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:15972"},{"text":"%pyspark\n#7\nx = sc.parallelize(['A','A','B'])\ny = x.distinct()\nprint(x.collect())\nprint(y.collect())\n","dateUpdated":"2018-03-22T06:30:47+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"['A', 'A', 'B']\n['A', 'B']\n"}]},"apps":[],"jobName":"paragraph_1521699681263_-1397196748","id":"20180318-213034_1360509328","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:15973"},{"text":"%md\n### sample(withReplacement, fraction, seed=None)\nReturn a sampled subset of this RDD.\n","dateUpdated":"2018-03-22T06:30:47+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>sample(withReplacement, fraction, seed=None)</h3>\n<p>Return a sampled subset of this RDD.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681264_-1386808528","id":"20180320-232726_1499567723","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:15974"},{"text":"%md\n![SPARK](https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page10.svg)\n","dateUpdated":"2018-03-22T06:30:47+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><img src=\"https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page10.svg\" alt=\"SPARK\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681264_-1386808528","id":"20180321-000332_1645505114","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:15975"},{"text":"%spark\n//8\nval x = sc.parallelize(0 to 6)\nval y=x.sample(false, 0.5)\ny.collect","dateUpdated":"2018-03-22T06:30:48+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"x: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[36] at parallelize at <console>:28\ny: org.apache.spark.rdd.RDD[Int] = PartitionwiseSampledRDD[39] at sample at <console>:29\nres22: Array[Int] = Array(1, 2, 3, 4, 5, 6)\n"}]},"apps":[],"jobName":"paragraph_1521699681264_-1386808528","id":"20180318-213141_1058874873","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:15976"},{"text":"%pyspark\n#8\nx = sc.parallelize(range(7))\ny = x.sample(withReplacement=False, fraction=0.5)\nprint(y.collect())\n","dateUpdated":"2018-03-22T06:30:48+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[1, 2, 5]\n"}]},"apps":[],"jobName":"paragraph_1521699681264_-1386808528","id":"20180318-213147_1737859064","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:15977"},{"text":"%md\n### takeSample(withReplacement, num, seed=None)\nReturn a fixed-size sampled subset of this RDD.\n","dateUpdated":"2018-03-22T06:30:48+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>takeSample(withReplacement, num, seed=None)</h3>\n<p>Return a fixed-size sampled subset of this RDD.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681264_-1386808528","id":"20180320-232745_345567894","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:15978"},{"text":"%md\n![SPARK](https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page11.svg)\n","dateUpdated":"2018-03-22T06:30:48+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><img src=\"https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page11.svg\" alt=\"SPARK\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681264_-1386808528","id":"20180321-000403_1628269554","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:15979"},{"text":"%spark\n//9\nval x = sc.parallelize(1 to 6)\nval y = x.takeSample(false, 3) \nprintln(y.mkString(\" \"))\n","dateUpdated":"2018-03-22T06:30:48+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"x: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[41] at parallelize at <console>:28\ny: Array[Int] = Array(1, 5, 2)\n1 5 2\n"}]},"apps":[],"jobName":"paragraph_1521699681264_-1386808528","id":"20180318-213248_818507511","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:15980"},{"text":"%pyspark\n#9\nx = sc.parallelize(range(7))\ny = x.takeSample(withReplacement=False, num=3) \nprint(y)","dateUpdated":"2018-03-22T06:30:48+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[6, 3, 5]\n"}]},"apps":[],"jobName":"paragraph_1521699681264_-1386808528","id":"20180318-214153_1993498112","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:15981"},{"text":"%md\n### union(other)\nReturn the union of this RDD and another one.\n","dateUpdated":"2018-03-22T06:30:49+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>union(other)</h3>\n<p>Return the union of this RDD and another one.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681264_-1386808528","id":"20180320-232801_112676387","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:15982"},{"text":"%md\n![SPARK](https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page12.svg)\n","dateUpdated":"2018-03-22T06:30:49+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><img src=\"https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page12.svg\" alt=\"SPARK\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681264_-1386808528","id":"20180321-000413_1585541706","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:15983"},{"text":"%spark\n//10\nval x = sc.parallelize(Array('A','A','B'))\nval y = sc.parallelize(Array('D','C','A'))\nval z = x.union(y)\nz.collect\n","dateUpdated":"2018-03-22T06:30:49+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"x: org.apache.spark.rdd.RDD[Char] = ParallelCollectionRDD[45] at parallelize at <console>:28\ny: org.apache.spark.rdd.RDD[Char] = ParallelCollectionRDD[49] at parallelize at <console>:27\nz: org.apache.spark.rdd.RDD[Char] = UnionRDD[50] at union at <console>:31\nres26: Array[Char] = Array(A, A, B, D, C, A)\n"}]},"apps":[],"jobName":"paragraph_1521699681264_-1386808528","id":"20180318-214240_1125287188","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:15984"},{"text":"%pyspark\n#10\nx = sc.parallelize(['A','A','B'])\ny = sc.parallelize(['D','C','A'])\nz = x.union(y)\nprint(z.collect())","dateUpdated":"2018-03-22T06:30:49+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"['A', 'A', 'B', 'D', 'C', 'A']\n"}]},"apps":[],"jobName":"paragraph_1521699681264_-1386808528","id":"20180318-215858_480938337","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:15985"},{"text":"%md\n### intersection(other)\nReturn the intersection of this RDD and another one. The output will not contain any duplicate elements, even if the input RDDs did","dateUpdated":"2018-03-22T06:30:49+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>intersection(other)</h3>\n<p>Return the intersection of this RDD and another one. The output will not contain any duplicate elements, even if the input RDDs did</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681264_-1386808528","id":"20180320-232825_1996222066","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:15986"},{"text":"%md\n![SPARK](https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page13.svg)\n","dateUpdated":"2018-03-22T06:30:49+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><img src=\"https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page13.svg\" alt=\"SPARK\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681265_-1387193277","id":"20180321-000422_795740776","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:15987"},{"text":"%spark\n//11\nval x = sc.parallelize(Array('A','A','B'))\nval y = sc.parallelize(Array('D','C','A'))\nval z = x.intersection(y)\nz.collect\n\n","dateUpdated":"2018-03-22T06:30:50+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"x: org.apache.spark.rdd.RDD[Char] = ParallelCollectionRDD[51] at parallelize at <console>:28\ny: org.apache.spark.rdd.RDD[Char] = ParallelCollectionRDD[62] at parallelize at <console>:27\nz: org.apache.spark.rdd.RDD[Char] = MapPartitionsRDD[68] at intersection at <console>:31\nres28: Array[Char] = Array(A)\n"}]},"apps":[],"jobName":"paragraph_1521699681265_-1387193277","id":"20180318-220023_1541997905","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:15988"},{"text":"%pyspark\n#11\nx = sc.parallelize(['A','A','B'])\ny = sc.parallelize(['D','C','A'])\nz = x.intersection(y)\nprint(z.collect())","dateUpdated":"2018-03-22T06:30:50+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"['A']\n"}]},"apps":[],"jobName":"paragraph_1521699681265_-1387193277","id":"20180318-220129_1180878632","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:15989"},{"text":"%md\n### sortByKey(ascending=True, numPartitions=None, keyfunc=<function <lambda> at 0x7f51f1ab5050>)\nSorts this RDD, which is assumed to consist of (key, value) pairs\n","dateUpdated":"2018-03-22T06:30:50+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>sortByKey(ascending=True, numPartitions=None, keyfunc=&lt;function <lambda> at 0x7f51f1ab5050&gt;)</h3>\n<p>Sorts this RDD, which is assumed to consist of (key, value) pairs</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681265_-1387193277","id":"20180320-232848_74427017","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:15990"},{"text":"%md\n![SPARK](https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page14.svg)\n","dateUpdated":"2018-03-22T06:30:50+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><img src=\"https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page14.svg\" alt=\"SPARK\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681265_-1387193277","id":"20180321-000431_564960272","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:15991"},{"text":"%spark\n//12\nval x = sc.parallelize(Array(('B',1),('A',2),('C',3)))\nval y = x.sortByKey()\ny.collect()\n","dateUpdated":"2018-03-22T06:30:50+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"x: org.apache.spark.rdd.RDD[(Char, Int)] = ParallelCollectionRDD[69] at parallelize at <console>:28\ny: org.apache.spark.rdd.RDD[(Char, Int)] = ShuffledRDD[80] at sortByKey at <console>:29\nres30: Array[(Char, Int)] = Array((A,2), (B,1), (C,3))\n"}]},"apps":[],"jobName":"paragraph_1521699681265_-1387193277","id":"20180318-220219_1182854034","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:15992"},{"text":"%pyspark\n#12\nx = sc.parallelize([('B',1),('A',2),('C',3)])\ny = x.sortByKey()\nprint(y.collect())\n","dateUpdated":"2018-03-22T06:30:50+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[('A', 2), ('B', 1), ('C', 3)]\n"}]},"apps":[],"jobName":"paragraph_1521699681265_-1387193277","id":"20180318-220254_1724838301","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:15993"},{"text":"%md\n### sortBy(keyfunc, ascending=True, numPartitions=None)\nSorts this RDD by the given keyfunc","dateUpdated":"2018-03-22T06:30:51+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>sortBy(keyfunc, ascending=True, numPartitions=None)</h3>\n<p>Sorts this RDD by the given keyfunc</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681265_-1387193277","id":"20180320-232931_928546581","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:15994"},{"text":"%md\n![SPARK](https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page15.svg)\n","dateUpdated":"2018-03-22T06:30:51+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><img src=\"https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page15.svg\" alt=\"SPARK\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681265_-1387193277","id":"20180321-000444_2119869817","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:15995"},{"text":"%spark\n//13\nval x = sc.parallelize(Array(\"black\",\"yellow\",\"orange\"))\nval y = x.sortBy(x=>x.split(\",\")(0))\ny.collect\n","dateUpdated":"2018-03-22T06:30:51+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"x: org.apache.spark.rdd.RDD[String] = ParallelCollectionRDD[81] at parallelize at <console>:28\ny: org.apache.spark.rdd.RDD[String] = MapPartitionsRDD[89] at sortBy at <console>:29\nres32: Array[String] = Array(black, orange, yellow)\n"}]},"apps":[],"jobName":"paragraph_1521699681265_-1387193277","id":"20180318-220345_832603528","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:15996"},{"text":"%pyspark\n#13\n# sortBy\nx = sc.parallelize(['Cat','Apple','Bat'])\ndef keyGen(val): return val[0]\ny = x.sortBy(keyGen)\nprint(y.collect())","dateUpdated":"2018-03-22T06:30:51+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"['Apple', 'Bat', 'Cat']\n"}]},"apps":[],"jobName":"paragraph_1521699681265_-1387193277","id":"20180318-220354_1335753315","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:15997"},{"text":"%md\n### glom()\nReturn an RDD created by coalescing all elements within each partition into a list.","dateUpdated":"2018-03-22T06:30:51+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>glom()</h3>\n<p>Return an RDD created by coalescing all elements within each partition into a list.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681266_-1386039030","id":"20180320-232948_323023473","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:15998"},{"text":"%md\n![SPARK](https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page16.svg)\n","dateUpdated":"2018-03-22T06:30:51+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><img src=\"https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page16.svg\" alt=\"SPARK\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681266_-1386039030","id":"20180321-000454_630538225","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:15999"},{"text":"%spark\n//14\nval x = sc.parallelize(Array('C','B','A'), 2)\nval y = x.glom()\nx.collect\ny.collect","dateUpdated":"2018-03-22T06:30:52+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"x: org.apache.spark.rdd.RDD[Char] = ParallelCollectionRDD[95] at parallelize at <console>:28\ny: org.apache.spark.rdd.RDD[Array[Char]] = MapPartitionsRDD[98] at glom at <console>:29\nres34: Array[Char] = Array(C, B, A)\nres35: Array[Array[Char]] = Array(Array(C), Array(B, A))\n"}]},"apps":[],"jobName":"paragraph_1521699681266_-1386039030","id":"20180318-220500_841038568","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16000"},{"text":"%pyspark\n#14\nx = sc.parallelize(['C','B','A'], 2)\ny = x.glom()\nprint(x.collect()) \nprint(y.collect())\n","dateUpdated":"2018-03-22T06:30:52+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"['C', 'B', 'A']\n[['C'], ['B', 'A']]\n"}]},"apps":[],"jobName":"paragraph_1521699681266_-1386039030","id":"20180318-221532_377738610","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16001"},{"text":"%md\n### cartesian(other)\nReturn the Cartesian product of this RDD and another one, that is, the RDD of all pairs of elements (a, b) where a is in self and b is in other.","dateUpdated":"2018-03-22T06:30:52+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>cartesian(other)</h3>\n<p>Return the Cartesian product of this RDD and another one, that is, the RDD of all pairs of elements (a, b) where a is in self and b is in other.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681266_-1386039030","id":"20180320-233115_1552721417","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16002"},{"text":"%md\n![SPARK](https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page17.svg)\n7","dateUpdated":"2018-03-22T06:30:52+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><img src=\"https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page17.svg\" alt=\"SPARK\" /><br/>7</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681266_-1386039030","id":"20180321-000505_1336434341","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16003"},{"text":"%spark\n//15\nval x = sc.parallelize(Array('A','B'))\nval y = sc.parallelize(Array('C','D'))\nval z = x.cartesian(y)\nz.collect()","dateUpdated":"2018-03-22T06:30:52+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"x: org.apache.spark.rdd.RDD[Char] = ParallelCollectionRDD[99] at parallelize at <console>:28\ny: org.apache.spark.rdd.RDD[Char] = ParallelCollectionRDD[103] at parallelize at <console>:27\nz: org.apache.spark.rdd.RDD[(Char, Char)] = CartesianRDD[104] at cartesian at <console>:31\nres37: Array[(Char, Char)] = Array((A,C), (A,D), (B,C), (B,D))\n"}]},"apps":[],"jobName":"paragraph_1521699681266_-1386039030","id":"20180318-221631_209575778","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16004"},{"text":"%pyspark\n#15\nx = sc.parallelize(['A','B'])\ny = sc.parallelize(['C','D'])\nz = x.cartesian(y)\nprint(z.collect())","dateUpdated":"2018-03-22T06:30:52+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[('A', 'C'), ('A', 'D'), ('B', 'C'), ('B', 'D')]\n"}]},"apps":[],"jobName":"paragraph_1521699681266_-1386039030","id":"20180318-221719_2146938991","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16005"},{"text":"%md\n### groupBy(f, numPartitions=None, partitionFunc=<function portable_hash at 0x7f51f1ac0668>)¶\nReturn an RDD of grouped items.\n","dateUpdated":"2018-03-22T06:30:53+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>groupBy(f, numPartitions=None, partitionFunc=<function portable_hash at 0x7f51f1ac0668>)¶</h3>\n<p>Return an RDD of grouped items.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681266_-1386039030","id":"20180320-233140_1928062841","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16006"},{"text":"%md\n![SPARK](https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page18.svg)\n","dateUpdated":"2018-03-22T06:30:53+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><img src=\"https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page18.svg\" alt=\"SPARK\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681266_-1386039030","id":"20180321-000525_1225782224","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16007"},{"text":"%spark\n//16\nval x = sc.parallelize(Array(\"Josep\", \"Jimmy\", \"Tina\", \"christi\", \"James\", \"Cory\",\"Ryan\", \"Jessica\", \"Juan\"), 3)\nval y = x.groupBy(word => word.charAt(0))\ny.collect\n","dateUpdated":"2018-03-22T06:30:53+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"x: org.apache.spark.rdd.RDD[String] = ParallelCollectionRDD[105] at parallelize at <console>:28\ny: org.apache.spark.rdd.RDD[(Char, Iterable[String])] = ShuffledRDD[113] at groupBy at <console>:29\nres39: Array[(Char, Iterable[String])] = Array((T,CompactBuffer(Tina)), (c,CompactBuffer(christi)), (R,CompactBuffer(Ryan)), (C,CompactBuffer(Cory)), (J,CompactBuffer(Josep, Jimmy, James, Jessica, Juan)))\n"}]},"apps":[],"jobName":"paragraph_1521699681266_-1386039030","id":"20180318-221841_1287475174","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16008"},{"text":"%pyspark\n#16\nx = sc.parallelize([1,2,3])\ny = x.groupBy(lambda x: 'A' if (x%2 == 1) else 'B' )\nprint(x.collect())\nprint([(j[0],[i for i in j[1]]) for j in y.collect()]) ","dateUpdated":"2018-03-22T06:30:53+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[1, 2, 3]\n[('A', [1, 3]), ('B', [2])]\n"}]},"apps":[],"jobName":"paragraph_1521699681266_-1386039030","id":"20180318-222034_2076703521","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16009"},{"text":"%md\n### pipe(command, env=None, checkCode=False)\nReturn an RDD created by piping elements to a forked external process.\n","dateUpdated":"2018-03-22T06:30:53+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>pipe(command, env=None, checkCode=False)</h3>\n<p>Return an RDD created by piping elements to a forked external process.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681267_-1386423779","id":"20180320-233205_304852744","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16010"},{"text":"%md\n![SPARK](https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page19.svg)\n","dateUpdated":"2018-03-22T06:30:53+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><img src=\"https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page19.svg\" alt=\"SPARK\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681267_-1386423779","id":"20180321-000533_1711853250","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16011"},{"text":"%spark\n// 17\nval a = sc.parallelize(1 to 9, 3)\na.glom.collect\na.pipe(\"head -n 1\").collect\n","dateUpdated":"2018-03-22T06:30:53+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"a: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[114] at parallelize at <console>:28\nres41: Array[Array[Int]] = Array(Array(1, 2, 3), Array(4, 5, 6), Array(7, 8, 9))\nres42: Array[String] = Array(1, 4, 7)\n"}]},"apps":[],"jobName":"paragraph_1521699681267_-1386423779","id":"20180318-222236_21956190","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16012"},{"text":"%pyspark\n# 17\nx = sc.parallelize(['A', 'Ba', 'C', 'AD'])\ny = x.pipe('grep -i A') \nprint(x.collect())\nprint(y.collect())","dateUpdated":"2018-03-22T06:30:54+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"['A', 'Ba', 'C', 'AD']\n[u'A', u'Ba', u'AD']\n"}]},"apps":[],"jobName":"paragraph_1521699681267_-1386423779","id":"20180318-222431_502340245","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16013"},{"text":"%md\n### foreach(f)\nApplies a function to all elements of this RDD.","dateUpdated":"2018-03-22T06:30:54+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>foreach(f)</h3>\n<p>Applies a function to all elements of this RDD.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681267_-1386423779","id":"20180320-233238_895368624","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16014"},{"text":"%md\n![SPARK](https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page20.svg)\n","dateUpdated":"2018-03-22T06:30:54+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><img src=\"https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page20.svg\" alt=\"SPARK\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681267_-1386423779","id":"20180321-000543_2034539804","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16015"},{"text":"%spark\n//18\nval x = sc.parallelize(1 to 6)\nval y = x.takeSample(false, 3) \ny.foreach(x=>println(x))\n","dateUpdated":"2018-03-22T06:30:54+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"x: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[119] at parallelize at <console>:28\ny: Array[Int] = Array(6, 5, 4)\n6\n5\n4\n"}]},"apps":[],"jobName":"paragraph_1521699681267_-1386423779","id":"20180318-222714_1410768982","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16016"},{"text":"%pyspark\n#18\nfrom __future__ import print_function\nx = sc.parallelize([1,2,3])\ndef f(el):\n    '''side effect: append the current RDD elements to a file'''\n    f1=open(\"./foreachExample.txt\", 'a+') \n    print(el,file=f1)\n\nopen('./foreachExample.txt', 'w').close()  # first clear the file contents\n\ny = x.foreach(f) # writes into foreachExample.txt\n\nprint(x.collect())\nprint(y) # foreach returns 'None'\n# print the contents of foreachExample.txt\nwith open(\"./foreachExample.txt\", \"r\") as foreachExample:\n    print (foreachExample.read())\n","dateUpdated":"2018-03-22T06:30:54+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[1, 2, 3]\nNone\n3\n2\n1\n\n"}]},"apps":[],"jobName":"paragraph_1521699681267_-1386423779","id":"20180318-223441_490490839","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16017"},{"text":"%md\n### mapPartitionsWithIndex(f, preservesPartitioning=False)\nReturn a new RDD by applying a function to each partition of this RDD, while tracking the index of the original partition.\n","dateUpdated":"2018-03-22T06:30:54+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>mapPartitionsWithIndex(f, preservesPartitioning=False)</h3>\n<p>Return a new RDD by applying a function to each partition of this RDD, while tracking the index of the original partition.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681267_-1386423779","id":"20180320-233325_1649607729","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16018"},{"text":"%md\n![SPARK](https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page21.svg)\n","dateUpdated":"2018-03-22T06:30:55+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><img src=\"https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page21.svg\" alt=\"SPARK\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681267_-1386423779","id":"20180321-000553_2036190301","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16019"},{"text":"%spark\n//19\nval parallel = sc.parallelize(1 to 9)\nval parts = parallel.partitions\nfor(p <- parts){\n  val idx = p.index\n  val partRDD = parallel.mapPartitionsWithIndex((index: Int, it: Iterator[Int]) => if(index == idx) it else Iterator(), true)\n  val data = partRDD.collect\n}\nparallel.foreachPartition(partition => {\n  partition.toArray\n})","dateUpdated":"2018-03-22T06:30:55+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"parallel: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[123] at parallelize at <console>:28\nparts: Array[org.apache.spark.Partition] = Array(org.apache.spark.rdd.ParallelCollectionPartition@1a44, org.apache.spark.rdd.ParallelCollectionPartition@1a45, org.apache.spark.rdd.ParallelCollectionPartition@1a46, org.apache.spark.rdd.ParallelCollectionPartition@1a47, org.apache.spark.rdd.ParallelCollectionPartition@1a48, org.apache.spark.rdd.ParallelCollectionPartition@1a49, org.apache.spark.rdd.ParallelCollectionPartition@1a4a, org.apache.spark.rdd.ParallelCollectionPartition@1a4b)\n"}]},"apps":[],"jobName":"paragraph_1521699681267_-1386423779","id":"20180318-223512_788069415","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16020"},{"text":"%pyspark\n#19\nfrom __future__ import print_function\nx = sc.parallelize([1,2,3],5)\ndef f(parition):\n    '''side effect: append the current RDD partition contents to a file'''\n    f1=open(\"./foreachPartitionExample.txt\", 'a+') \n    print([el for el in parition],file=f1)\n\nopen('./foreachPartitionExample.txt', 'w').close()  # first clear the file contents\n\ny = x.foreachPartition(f) # writes into foreachExample.txt\n\nprint(x.glom().collect())\nprint(y)  # foreach returns 'None'\n# print the contents of foreachExample.txt\nwith open(\"./foreachPartitionExample.txt\", \"r\") as foreachExample:\n    print (foreachExample.read())","dateUpdated":"2018-03-22T06:30:55+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[[], [1], [], [2], [3]]\nNone\n[]\n[]\n[2]\n[1]\n[3]\n\n"}]},"apps":[],"jobName":"paragraph_1521699681268_-1388347523","id":"20180318-223927_330921168","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16021"},{"text":"%md\n### collect()\nReturn a list that contains all of the elements in this RDD.\n\n> Note This method should only be used if the resulting array is expected to be small, as all the data is loaded into the driver’s memory.","dateUpdated":"2018-03-22T06:30:55+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>collect()</h3>\n<p>Return a list that contains all of the elements in this RDD.</p>\n<blockquote>\n  <p>Note This method should only be used if the resulting array is expected to be small, as all the data is loaded into the driver’s memory.</p>\n</blockquote>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681268_-1388347523","id":"20180320-233355_1384932015","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16022"},{"text":"%md\n![SPARK](https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page22.svg)\n","dateUpdated":"2018-03-22T06:30:55+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><img src=\"https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page22.svg\" alt=\"SPARK\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681268_-1388347523","id":"20180321-000604_1077358025","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16023"},{"text":"%spark\n//20\nval x = sc.parallelize(Array(1,2,3))\nx.collect()\n\n\n","dateUpdated":"2018-03-22T06:30:55+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"x: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[135] at parallelize at <console>:28\nres49: Array[Int] = Array(1, 2, 3)\n"}]},"apps":[],"jobName":"paragraph_1521699681268_-1388347523","id":"20180318-224338_233869257","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16024"},{"text":"%pyspark\n#20\nx = sc.parallelize([1,2,3])\ny = x.collect()\nprint(x)  # distributed\nprint(y) \n","dateUpdated":"2018-03-22T06:30:56+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"ParallelCollectionRDD[136] at parallelize at PythonRDD.scala:475\n[1, 2, 3]\n"}]},"apps":[],"jobName":"paragraph_1521699681268_-1388347523","id":"20180318-225948_1191363051","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16025"},{"text":"%md\n### reduce(f)\nReduces the elements of this RDD using the specified commutative and associative binary operator. Currently reduces partitions locally.\n","dateUpdated":"2018-03-22T06:30:56+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>reduce(f)</h3>\n<p>Reduces the elements of this RDD using the specified commutative and associative binary operator. Currently reduces partitions locally.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681268_-1388347523","id":"20180320-233444_85555462","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16026"},{"text":"%md\n![SPARK](https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page23.svg)","dateUpdated":"2018-03-22T06:30:56+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><img src=\"https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page23.svg\" alt=\"SPARK\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681268_-1388347523","id":"20180321-000621_1009641980","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16027"},{"text":"%spark\n//21\nval x = sc.parallelize(1 to 10, 2)\nval y = x.reduce((accum,n) => (accum + n)) \n","dateUpdated":"2018-03-22T06:30:56+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"x: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[137] at parallelize at <console>:28\ny: Int = 55\n"}]},"apps":[],"jobName":"paragraph_1521699681268_-1388347523","id":"20180318-230032_1968673642","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16028"},{"text":"%pyspark\n#21\nx = sc.parallelize([1,2,3])\ny = x.reduce(lambda obj, accumulated: obj + accumulated)  # computes a cumulative sum\nprint(x.collect())\nprint(y)\n","dateUpdated":"2018-03-22T06:30:56+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[1, 2, 3]\n6\n"}]},"apps":[],"jobName":"paragraph_1521699681268_-1388347523","id":"20180318-230220_141634760","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16029"},{"text":"%md\n### fold(zeroValue, op)\nAggregate the elements of each partition, and then the results for all the partitions, using a given associative function and a neutral “zero value.”\n","dateUpdated":"2018-03-22T06:30:56+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>fold(zeroValue, op)</h3>\n<p>Aggregate the elements of each partition, and then the results for all the partitions, using a given associative function and a neutral “zero value.”</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681269_-1388732272","id":"20180320-233502_1999350692","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16030"},{"text":"%md\n![SPARK](https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page24.svg)","user":"admin","dateUpdated":"2018-03-22T06:30:57+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><img src=\"https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page24.svg\" alt=\"SPARK\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681269_-1388732272","id":"20180321-000629_2114934881","dateCreated":"2018-03-22T06:21:21+0000","dateStarted":"2018-03-22T06:30:17+0000","dateFinished":"2018-03-22T06:30:17+0000","status":"FINISHED","progressUpdateIntervalMs":500,"$$hashKey":"object:16031"},{"text":"%spark\n//22\n val employeeData = sc.parallelize(List((\"Jack\",1000.0),(\"Bob\",2000.0),(\"Carl\",7000.0)))\n val maxSalaryEmployee = employeeData.fold(\"x\",0.0)((acc,employee) => { \nif(acc._2 < employee._2) employee else acc})\nprintln(\"employee with maximum salary is\"+maxSalaryEmployee)\n","dateUpdated":"2018-03-22T06:30:57+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"employeeData: org.apache.spark.rdd.RDD[(String, Double)] = ParallelCollectionRDD[140] at parallelize at <console>:28\nmaxSalaryEmployee: (String, Double) = (Carl,7000.0)\nemployee with maximum salary is(Carl,7000.0)\n"}]},"apps":[],"jobName":"paragraph_1521699681269_-1388732272","id":"20180318-230517_931815886","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16032"},{"text":"%pyspark\n\nx = sc.parallelize([1,2,3])\nneutral_zero_value = 0  # 0 for sum, 1 for multiplication\ny = x.fold(neutral_zero_value,lambda obj, accumulated: accumulated + obj) # computes cumulative sum\nprint(x.collect())\nprint(y)","dateUpdated":"2018-03-22T06:30:57+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"results":{},"enabled":true,"tableHide":true},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"Traceback (most recent call last):\n  File \"/tmp/zeppelin_pyspark-7509275970937683799.py\", line 344, in <module>\n    code = compile('\\n'.join(final_code), '<stdin>', 'exec', ast.PyCF_ONLY_AST, 1)\n  File \"<stdin>\", line 1\n    /#22\n    ^\nSyntaxError: invalid syntax\n"}]},"apps":[],"jobName":"paragraph_1521699681269_-1388732272","id":"20180318-230953_875927749","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16033"},{"text":"%md\n### aggregate(zeroValue, seqOp, combOp)\nAggregate the elements of each partition, and then the results for all the partitions, using a given combine functions and a neutral “zero value.”\n\nThe functions op(t1, t2) is allowed to modify t1 and return it as its result value to avoid object allocation; however, it should not modify t2.","dateUpdated":"2018-03-22T06:30:57+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>aggregate(zeroValue, seqOp, combOp)</h3>\n<p>Aggregate the elements of each partition, and then the results for all the partitions, using a given combine functions and a neutral “zero value.”</p>\n<p>The functions op(t1, t2) is allowed to modify t1 and return it as its result value to avoid object allocation; however, it should not modify t2.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681269_-1388732272","id":"20180320-233551_1355408755","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16034"},{"text":"%md\n![SPARK](https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page25.svg)","dateUpdated":"2018-03-22T06:30:57+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><img src=\"https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page25.svg\" alt=\"SPARK\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681269_-1388732272","id":"20180321-000640_105366040","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16035"},{"text":"%spark\n//23\nval inputrdd = sc.parallelize(List((\"maths\", 21),(\"english\", 22),(\"science\", 31)),3)\nval result = inputrdd.aggregate(3) ( (acc, value) => (acc + value._2),(acc1, acc2) => (acc1 + acc2))","dateUpdated":"2018-03-22T06:30:57+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"inputrdd: org.apache.spark.rdd.RDD[(String, Int)] = ParallelCollectionRDD[141] at parallelize at <console>:28\nresult: Int = 86\n"}]},"apps":[],"jobName":"paragraph_1521699681269_-1388732272","id":"20180318-230953_220337481","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16036"},{"text":"%pyspark\n#23\nx = sc.parallelize([2,3,4])\nneutral_zero_value = (0,1) # sum: x+0 = x, product: 1*x = x\nseqOp = (lambda aggregated, el: (aggregated[0] + el, aggregated[1] * el)) \ncombOp = (lambda aggregated, el: (aggregated[0] + el[0], aggregated[1] * el[1]))\ny = x.aggregate(neutral_zero_value,seqOp,combOp)  # computes (cumulative sum, cumulative product)\nprint(x.collect())\nprint(y)\n","dateUpdated":"2018-03-22T06:30:58+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[2, 3, 4]\n(9, 24)\n"}]},"apps":[],"jobName":"paragraph_1521699681269_-1388732272","id":"20180318-230221_1114007779","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16037"},{"text":"%md\n### max(key=None)\nFind the maximum item in this RDD.","dateUpdated":"2018-03-22T06:30:58+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>max(key=None)</h3>\n<p>Find the maximum item in this RDD.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681269_-1388732272","id":"20180320-233626_1091901554","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16038"},{"text":"%md\n![SPARK](https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page26.svg)","dateUpdated":"2018-03-22T06:30:58+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><img src=\"https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page26.svg\" alt=\"SPARK\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681269_-1388732272","id":"20180321-000649_223095479","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16039"},{"text":"%spark\n//24\nval x = sc.parallelize(Array(1,3,2))\nval y = x.max()\nprintln(y)\n","dateUpdated":"2018-03-22T06:30:58+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"x: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[144] at parallelize at <console>:28\ny: Int = 3\n3\n"}]},"apps":[],"jobName":"paragraph_1521699681269_-1388732272","id":"20180318-231344_1666339426","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16040"},{"text":"%pyspark\n#24\nx = sc.parallelize([1,3,2])\ny = x.max()\nprint(y)\n","dateUpdated":"2018-03-22T06:30:58+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"3\n"}]},"apps":[],"jobName":"paragraph_1521699681270_-1387578026","id":"20180318-231406_353912621","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16041"},{"text":"%md\n### min(key=None)\nFind the minimum item in this RDD.","dateUpdated":"2018-03-22T06:30:58+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>min(key=None)</h3>\n<p>Find the minimum item in this RDD.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681270_-1387578026","id":"20180320-233645_343385377","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16042"},{"text":"%md\n![SPARK](https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page27.svg)","dateUpdated":"2018-03-22T06:30:59+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><img src=\"https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page27.svg\" alt=\"SPARK\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681270_-1387578026","id":"20180321-000657_244811436","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16043"},{"text":"%spark\n//25\nval x = sc.parallelize(Array(1,3,2))\nval y = x.min()\nprintln(y)\n","dateUpdated":"2018-03-22T06:30:59+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"x: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[147] at parallelize at <console>:28\ny: Int = 1\n1\n"}]},"apps":[],"jobName":"paragraph_1521699681270_-1387578026","id":"20180318-231514_1015642283","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16044"},{"text":"%pyspark\n#25\nx = sc.parallelize([1,3,2])\ny = x.min()\nprint(y)\n","dateUpdated":"2018-03-22T06:30:59+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"1\n"}]},"apps":[],"jobName":"paragraph_1521699681270_-1387578026","id":"20180318-231515_1596880504","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16045"},{"text":"%md\n### sum()\nAdd up the elements in this RDD.","dateUpdated":"2018-03-22T06:30:59+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>sum()</h3>\n<p>Add up the elements in this RDD.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681270_-1387578026","id":"20180320-233704_1598630070","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16046"},{"text":"%md\n![SPARK](https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page28.svg)","dateUpdated":"2018-03-22T06:30:59+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><img src=\"https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page28.svg\" alt=\"SPARK\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681270_-1387578026","id":"20180321-000706_740176932","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16047"},{"text":"%spark\n//26\nval x = sc.parallelize(Array(1,3,2))\nval y = x.sum()\nprintln(y)","dateUpdated":"2018-03-22T06:30:59+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"x: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[150] at parallelize at <console>:28\ny: Double = 6.0\n6.0\n"}]},"apps":[],"jobName":"paragraph_1521699681270_-1387578026","id":"20180318-231554_373828821","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16048"},{"text":"%pyspark\n#26\nx = sc.parallelize([1,3,2])\ny = x.sum()\nprint(y)","dateUpdated":"2018-03-22T06:31:00+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"6\n"}]},"apps":[],"jobName":"paragraph_1521699681270_-1387578026","id":"20180318-231611_754040865","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16049"},{"text":"%md\n### count()\nReturn the number of elements in this RDD.\n","dateUpdated":"2018-03-22T06:31:00+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>count()</h3>\n<p>Return the number of elements in this RDD.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681270_-1387578026","id":"20180320-233736_1637825563","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16050"},{"text":"%md\n![SPARK](https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page29.svg)","dateUpdated":"2018-03-22T06:31:00+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><img src=\"https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page29.svg\" alt=\"SPARK\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681270_-1387578026","id":"20180321-000714_1039773891","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16051"},{"text":"%spark\n//27\nval x = sc.parallelize(Array(1,3,2))\nval y = x.count\nprintln(y)","dateUpdated":"2018-03-22T06:31:00+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"x: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[154] at parallelize at <console>:28\ny: Long = 3\n3\n"}]},"apps":[],"jobName":"paragraph_1521699681270_-1387578026","id":"20180318-231727_930611032","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16052"},{"text":"%pyspark\n#27\nx = sc.parallelize([1,3,2])\ny = x.count()\nprint(y)","dateUpdated":"2018-03-22T06:31:00+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"3\n"}]},"apps":[],"jobName":"paragraph_1521699681271_-1387962774","id":"20180318-231728_1016974474","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16053"},{"text":"%md\n### histogram(buckets)\nCompute a histogram using the provided buckets. The buckets are all open to the right except for the last which is closed. e.g. [1,10,20,50] means the buckets are [1,10) [10,20) [20,50], which means 1<=x<10, 10<=x<20, 20<=x<=50. And on the input of 1 and 50 we would have a histogram of 1,0,1.\n\nIf your histogram is evenly spaced (e.g. [0, 10, 20, 30]), this can be switched from an O(log n) inseration to O(1) per element (where n is the number of buckets).\n\nBuckets must be sorted, not contain any duplicates, and have at least two elements.\n","dateUpdated":"2018-03-22T06:31:00+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>histogram(buckets)</h3>\n<p>Compute a histogram using the provided buckets. The buckets are all open to the right except for the last which is closed. e.g. [1,10,20,50] means the buckets are [1,10) [10,20) [20,50], which means 1&lt;=x&lt;10, 10&lt;=x&lt;20, 20&lt;=x&lt;=50. And on the input of 1 and 50 we would have a histogram of 1,0,1.</p>\n<p>If your histogram is evenly spaced (e.g. [0, 10, 20, 30]), this can be switched from an O(log n) inseration to O(1) per element (where n is the number of buckets).</p>\n<p>Buckets must be sorted, not contain any duplicates, and have at least two elements.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681271_-1387962774","id":"20180320-233815_1926181984","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16054"},{"text":"%md\n![SPARK](https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page30.svg)","dateUpdated":"2018-03-22T06:31:01+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><img src=\"https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page30.svg\" alt=\"SPARK\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681271_-1387962774","id":"20180321-000724_348778062","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16055"},{"text":"%spark\n//28\nval x = sc.parallelize(Array(1,3,1,2,3))\nval y = x.histogram(2)\n","dateUpdated":"2018-03-22T06:31:01+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"x: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[157] at parallelize at <console>:28\ny: (Array[Double], Array[Long]) = (Array(1.0, 2.0, 3.0),Array(2, 3))\n"}]},"apps":[],"jobName":"paragraph_1521699681271_-1387962774","id":"20180318-231811_153328223","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16056"},{"text":"%pyspark\n#28\nx = sc.parallelize([1,3,1,2,3])\ny = x.histogram(buckets = 2)\nprint(y)","dateUpdated":"2018-03-22T06:31:01+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"([1, 2, 3], [2, 3])\n"}]},"apps":[],"jobName":"paragraph_1521699681271_-1387962774","id":"20180318-231842_716570349","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16057"},{"text":"%md\n### mean()\nCompute the mean of this RDD’s elements.","dateUpdated":"2018-03-22T06:31:01+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>mean()</h3>\n<p>Compute the mean of this RDD’s elements.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681271_-1387962774","id":"20180320-233842_1178741350","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16058"},{"text":"%md\n![SPARK](https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page31.svg)","dateUpdated":"2018-03-22T06:31:01+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><img src=\"https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page31.svg\" alt=\"SPARK\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681271_-1387962774","id":"20180321-000753_3357714","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16059"},{"text":"%spark\n//29\nval x = sc.parallelize(Array(1,3,1,2,3))\nval y = x.mean\nprintln(y)\n","dateUpdated":"2018-03-22T06:31:01+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"x: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[164] at parallelize at <console>:28\ny: Double = 2.0\n2.0\n"}]},"apps":[],"jobName":"paragraph_1521699681271_-1387962774","id":"20180318-232312_447300616","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16060"},{"text":"%pyspark\n#29\nx = sc.parallelize([1,3,1,2,3])\ny = x.mean()\nprint(y)","dateUpdated":"2018-03-22T06:31:02+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"2.0\n"}]},"apps":[],"jobName":"paragraph_1521699681271_-1387962774","id":"20180318-232341_1966280371","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16061"},{"text":"%md\n### variance()\nCompute the variance of this RDD’s elements.\n","dateUpdated":"2018-03-22T06:31:02+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>variance()</h3>\n<p>Compute the variance of this RDD’s elements.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681271_-1387962774","id":"20180320-233900_1646286172","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16062"},{"text":"%md\n![SPARK](https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page32.svg)","dateUpdated":"2018-03-22T06:31:02+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><img src=\"https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page32.svg\" alt=\"SPARK\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681271_-1387962774","id":"20180321-000801_246532029","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16063"},{"text":"%spark\n//30\nval x = sc.parallelize(Array(1,3,1,2,3))\nval y = x.variance\nprintln(y)","dateUpdated":"2018-03-22T06:31:02+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"x: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[169] at parallelize at <console>:28\ny: Double = 0.8\n0.8\n"}]},"apps":[],"jobName":"paragraph_1521699681271_-1387962774","id":"20180318-232441_604561204","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16064"},{"text":"%pyspark\n#30\nx = sc.parallelize([1,3,2])\ny = x.variance()  # divides by N\nprint(x.collect())\nprint(y)","dateUpdated":"2018-03-22T06:31:02+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[1, 3, 2]\n0.666666666667\n"}]},"apps":[],"jobName":"paragraph_1521699681272_-1389886519","id":"20180318-232457_1898828142","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16065"},{"text":"%md\n### stdev()\nCompute the standard deviation of this RDD’s elements.\n","dateUpdated":"2018-03-22T06:31:02+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>stdev()</h3>\n<p>Compute the standard deviation of this RDD’s elements.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681272_-1389886519","id":"20180320-233923_1790457521","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16066"},{"text":"%md\n![SPARK](https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page33.svg)\n","dateUpdated":"2018-03-22T06:31:02+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><img src=\"https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page33.svg\" alt=\"SPARK\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681272_-1389886519","id":"20180321-000811_640806738","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16067"},{"text":"%spark\n//31\nval x = sc.parallelize(Array(1,3,2))\nval y = x.stdev\nprintln(y)\n\n","dateUpdated":"2018-03-22T06:31:03+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"x: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[174] at parallelize at <console>:28\ny: Double = 0.816496580927726\n0.816496580927726\n"}]},"apps":[],"jobName":"paragraph_1521699681272_-1389886519","id":"20180318-232552_1052404376","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16068"},{"text":"%pyspark\n#31\nx = sc.parallelize([1,3,2])\ny = x.stdev()  # divides by N\nprint(x.collect())\nprint(y)","dateUpdated":"2018-03-22T06:31:03+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[1, 3, 2]\n0.816496580928\n"}]},"apps":[],"jobName":"paragraph_1521699681272_-1389886519","id":"20180318-232653_2047329814","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16069"},{"text":"%md\n### sampleStdev()\nCompute the sample standard deviation of this RDD’s elements (which corrects for bias in estimating the standard deviation by dividing by N-1 instead of N).","dateUpdated":"2018-03-22T06:31:03+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>sampleStdev()</h3>\n<p>Compute the sample standard deviation of this RDD’s elements (which corrects for bias in estimating the standard deviation by dividing by N-1 instead of N).</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681272_-1389886519","id":"20180320-233946_1405333066","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16070"},{"text":"%md\n![SPARK](https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page34.svg)","dateUpdated":"2018-03-22T06:31:03+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><img src=\"https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page34.svg\" alt=\"SPARK\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681272_-1389886519","id":"20180321-000820_1167995916","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16071"},{"text":"%spark\n//32\nval x = sc.parallelize(Array1,3,2))\nval y = x.sampleStdev() \nprint(y)\n","dateUpdated":"2018-03-22T06:31:03+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"ERROR","msg":[{"type":"TEXT","data":"<console>:2: error: ';' expected but ')' found.\nval x = sc.parallelize(Array1,3,2))\n                                  ^\n"}]},"apps":[],"jobName":"paragraph_1521699681272_-1389886519","id":"20180318-232806_177020547","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16072"},{"text":"%pyspark\n#32\nx = sc.parallelize([1,3,2])\ny = x.sampleStdev()\nprint(y)\n","dateUpdated":"2018-03-22T06:31:03+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"1.0\n"}]},"apps":[],"jobName":"paragraph_1521699681272_-1389886519","id":"20180318-232807_939887544","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16073"},{"text":"%md\n### sampleVariance()\nCompute the sample variance of this RDD’s elements (which corrects for bias in estimating the variance by dividing by N-1 instead of N).\n","dateUpdated":"2018-03-22T06:31:04+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>sampleVariance()</h3>\n<p>Compute the sample variance of this RDD’s elements (which corrects for bias in estimating the variance by dividing by N-1 instead of N).</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681272_-1389886519","id":"20180320-234006_517114913","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16074"},{"text":"%md\n![SPARK](https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page35.svg)","dateUpdated":"2018-03-22T06:31:04+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><img src=\"https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page35.svg\" alt=\"SPARK\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681272_-1389886519","id":"20180321-000829_1448433741","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16075"},{"text":"%spark\n//33\nval x = sc.parallelize(Array(1,3,2))\nval y = x.sampleVariance\nprint(y)\n","dateUpdated":"2018-03-22T06:31:04+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"x: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[181] at parallelize at <console>:28\ny: Double = 1.0\n1.0"}]},"apps":[],"jobName":"paragraph_1521699681273_-1390271268","id":"20180318-232904_1361541954","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16076"},{"text":"%pyspark\n#33\nx = sc.parallelize([1,3,2])\ny = x.sampleVariance() \nprint(y)\n","dateUpdated":"2018-03-22T06:31:04+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"1.0\n"}]},"apps":[],"jobName":"paragraph_1521699681273_-1390271268","id":"20180318-232904_1933287234","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16077"},{"text":"%md\n### countByValue()\nReturn the count of each unique value in this RDD as a dictionary of (value, count) pairs.","dateUpdated":"2018-03-22T06:31:04+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>countByValue()</h3>\n<p>Return the count of each unique value in this RDD as a dictionary of (value, count) pairs.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681273_-1390271268","id":"20180320-234032_445468071","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16078"},{"text":"%md\n![SPARK](https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page36.svg)\n","dateUpdated":"2018-03-22T06:31:04+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><img src=\"https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page36.svg\" alt=\"SPARK\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681273_-1390271268","id":"20180321-000838_1406084887","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16079"},{"text":"%spark\n//33\nval x = sc.parallelize(Array(1,3,1,2,3))\nval y = x.countByValue\nprint(y)\n","dateUpdated":"2018-03-22T06:31:05+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"x: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[186] at parallelize at <console>:28\ny: scala.collection.Map[Int,Long] = Map(1 -> 2, 2 -> 1, 3 -> 2)\nMap(1 -> 2, 2 -> 1, 3 -> 2)"}]},"apps":[],"jobName":"paragraph_1521699681273_-1390271268","id":"20180318-232910_1763749743","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16080"},{"text":"%pyspark\n#33\nx = sc.parallelize([1,3,1,2,3])\ny = x.countByValue()\nprint(y)\n","dateUpdated":"2018-03-22T06:31:05+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"defaultdict(<type 'int'>, {1: 2, 2: 1, 3: 2})\n"}]},"apps":[],"jobName":"paragraph_1521699681273_-1390271268","id":"20180318-232912_56312694","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16081"},{"text":"%md\n### top(num, key=None)\nGet the top N elements from an RDD.\n","dateUpdated":"2018-03-22T06:31:05+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>top(num, key=None)</h3>\n<p>Get the top N elements from an RDD.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681273_-1390271268","id":"20180320-234052_976573976","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16082"},{"text":"%md\n![SPARK](https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page37.svg)","dateUpdated":"2018-03-22T06:31:05+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><img src=\"https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page37.svg\" alt=\"SPARK\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681273_-1390271268","id":"20180321-000848_150290344","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16083"},{"text":"%spark\n//34\nval x = sc.parallelize(Array(1,3,1,2,3))\nval y = x.top(3)\nprintln(y.mkString(\" \"))\n","dateUpdated":"2018-03-22T06:31:05+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"x: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[192] at parallelize at <console>:28\ny: Array[Int] = Array(3, 3, 2)\n3 3 2\n"}]},"apps":[],"jobName":"paragraph_1521699681273_-1390271268","id":"20180318-232913_1924590822","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16084"},{"text":"%pyspark\n#34\nx = sc.parallelize([1,3,1,2,3])\ny = x.top(num = 3)\nprint(y)","dateUpdated":"2018-03-22T06:31:05+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[3, 3, 2]\n"}]},"apps":[],"jobName":"paragraph_1521699681273_-1390271268","id":"20180318-232913_113603135","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16085"},{"text":"%md\n### takeOrdered(num, key=None)\nGet the N elements from an RDD ordered in ascending order or as specified by the optional key function.\n","dateUpdated":"2018-03-22T06:31:06+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>takeOrdered(num, key=None)</h3>\n<p>Get the N elements from an RDD ordered in ascending order or as specified by the optional key function.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681274_-1389117021","id":"20180320-234111_841228510","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16086"},{"text":"%md\n![SPARK](https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page38.svg)","dateUpdated":"2018-03-22T06:31:06+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><img src=\"https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page38.svg\" alt=\"SPARK\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681274_-1389117021","id":"20180321-000906_2118663030","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16087"},{"text":"%spark\n//35\nval x = sc.parallelize(Array(1,3,1,2,3))\nval y = x.takeOrdered(3)\nprintln(y.mkString(\" \"))\n","dateUpdated":"2018-03-22T06:31:06+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"x: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[196] at parallelize at <console>:28\ny: Array[Int] = Array(1, 1, 2)\n1 1 2\n"}]},"apps":[],"jobName":"paragraph_1521699681274_-1389117021","id":"20180318-232913_584801549","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16088"},{"text":"%pyspark\n#35\nx = sc.parallelize([1,3,1,2,3])\ny = x.takeOrdered(num = 3)\nprint(y)\n","dateUpdated":"2018-03-22T06:31:06+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[1, 1, 2]\n"}]},"apps":[],"jobName":"paragraph_1521699681274_-1389117021","id":"20180318-232913_233610397","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16089"},{"text":"%md\n### take(num)\nTake the first num elements of the RDD.\n\nIt works by first scanning one partition, and use the results from that partition to estimate the number of additional partitions needed to satisfy the limit.\n\nTranslated from the Scala implementation in RDD","dateUpdated":"2018-03-22T06:31:06+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>take(num)</h3>\n<p>Take the first num elements of the RDD.</p>\n<p>It works by first scanning one partition, and use the results from that partition to estimate the number of additional partitions needed to satisfy the limit.</p>\n<p>Translated from the Scala implementation in RDD</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681274_-1389117021","id":"20180320-234134_1895896222","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16090"},{"text":"%md\n![SPARK](https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page39.svg)","dateUpdated":"2018-03-22T06:31:06+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><img src=\"https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page39.svg\" alt=\"SPARK\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681274_-1389117021","id":"20180321-000914_1074722764","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16091"},{"text":"%spark\n//36\nval x = sc.parallelize(Array(1,3,1,2,3))\nval y = x.take(3)\nprintln(y.mkString(\" \"))","dateUpdated":"2018-03-22T06:31:07+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"x: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[200] at parallelize at <console>:28\ny: Array[Int] = Array(1, 3, 1)\n1 3 1\n"}]},"apps":[],"jobName":"paragraph_1521699681274_-1389117021","id":"20180318-232913_1967467715","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16092"},{"text":"%pyspark\n#36\nx = sc.parallelize([1,3,1,2,3])\ny = x.take(num = 3)\nprint(x.collect())\nprint(y)\n","dateUpdated":"2018-03-22T06:31:07+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[1, 3, 1, 2, 3]\n[1, 3, 1]\n"}]},"apps":[],"jobName":"paragraph_1521699681274_-1389117021","id":"20180318-232913_558853933","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16093"},{"text":"%md\n### first()\nReturn the first element in this RDD","dateUpdated":"2018-03-22T06:31:07+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>first()</h3>\n<p>Return the first element in this RDD</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681274_-1389117021","id":"20180320-234207_1661607579","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16094"},{"text":"%md\n![SPARK](https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page40.svg)","dateUpdated":"2018-03-22T06:31:07+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><img src=\"https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page40.svg\" alt=\"SPARK\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681274_-1389117021","id":"20180321-000924_961414505","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16095"},{"text":"%spark\n//37\nval x = sc.parallelize(Array(1,3,1,2,3))\nval y = x.first()\nprint(y)\n","dateUpdated":"2018-03-22T06:31:07+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"x: org.apache.spark.rdd.RDD[Int] = ParallelCollectionRDD[204] at parallelize at <console>:28\ny: Int = 1\n1"}]},"apps":[],"jobName":"paragraph_1521699681275_-1389501770","id":"20180318-232910_2111502512","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16096"},{"text":"%pyspark\n#37\nx = sc.parallelize([1,3,1,2,3])\ny = x.first()\nprint(y)","dateUpdated":"2018-03-22T06:31:07+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"1\n"}]},"apps":[],"jobName":"paragraph_1521699681275_-1389501770","id":"20180318-232911_127611532","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16097"},{"text":"%md\n### collectAsMap()\nReturn the key-value pairs in this RDD to the master as a dictionary.\n\nNote this method should only be used if the resulting data is expected to be small, as all the data is loaded into the driver’s memory.","dateUpdated":"2018-03-22T06:31:08+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>collectAsMap()</h3>\n<p>Return the key-value pairs in this RDD to the master as a dictionary.</p>\n<p>Note this method should only be used if the resulting data is expected to be small, as all the data is loaded into the driver’s memory.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681275_-1389501770","id":"20180320-234236_1200001384","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16098"},{"text":"%md\n![SPARK](https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page41.svg)","dateUpdated":"2018-03-22T06:31:08+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><img src=\"https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page41.svg\" alt=\"SPARK\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681275_-1389501770","id":"20180321-000938_726261470","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16099"},{"text":"%spark\n//38\nval x = sc.parallelize(Array(('C',3),('A',1),('B',2)))\nval y = x.collectAsMap()\nprint(y)\n","dateUpdated":"2018-03-22T06:31:08+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"x: org.apache.spark.rdd.RDD[(Char, Int)] = ParallelCollectionRDD[208] at parallelize at <console>:28\ny: scala.collection.Map[Char,Int] = Map(A -> 1, C -> 3, B -> 2)\nMap(A -> 1, C -> 3, B -> 2)"}]},"apps":[],"jobName":"paragraph_1521699681275_-1389501770","id":"20180318-232911_1121485312","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16100"},{"text":"%pyspark\n#38\nx = sc.parallelize([('C',3),('A',1),('B',2)])\ny = x.collectAsMap()\nprint(y)","dateUpdated":"2018-03-22T06:31:08+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"{'A': 1, 'C': 3, 'B': 2}\n"}]},"apps":[],"jobName":"paragraph_1521699681275_-1389501770","id":"20180318-232911_737548601","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16101"},{"text":"%md\n### keys()\nReturn an RDD with the keys of each tuple.","dateUpdated":"2018-03-22T06:31:08+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>keys()</h3>\n<p>Return an RDD with the keys of each tuple.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681275_-1389501770","id":"20180320-234257_1846747431","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16102"},{"text":"%md\n![SPARK](https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page42.svg)","dateUpdated":"2018-03-22T06:31:08+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><img src=\"https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page42.svg\" alt=\"SPARK\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681275_-1389501770","id":"20180321-001003_692502045","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16103"},{"text":"%spark\n//39\nval x = sc.parallelize(Array(('C',3),('A',1),('B',2)))\nx.keys.collect","dateUpdated":"2018-03-22T06:31:09+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"x: org.apache.spark.rdd.RDD[(Char, Int)] = ParallelCollectionRDD[210] at parallelize at <console>:28\nres85: Array[Char] = Array(C, A, B)\n"}]},"apps":[],"jobName":"paragraph_1521699681275_-1389501770","id":"20180318-232911_874763746","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16104"},{"text":"%pyspark\n#39\nx = sc.parallelize([('C',3),('A',1),('B',2)])\ny = x.keys()\nprint(y.collect())\n","dateUpdated":"2018-03-22T06:31:09+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"['C', 'A', 'B']\n"}]},"apps":[],"jobName":"paragraph_1521699681275_-1389501770","id":"20180318-232903_620019861","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16105"},{"text":"%md\n### values()\nReturn an RDD with the values of each tuple.\n\n","dateUpdated":"2018-03-22T06:31:09+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>values()</h3>\n<p>Return an RDD with the values of each tuple.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681276_-1391425515","id":"20180320-234318_385595919","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16106"},{"text":"%md\n![SPARK](https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page43.svg)","dateUpdated":"2018-03-22T06:31:09+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><img src=\"https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page43.svg\" alt=\"SPARK\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681276_-1391425515","id":"20180321-001013_364872415","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16107"},{"text":"%spark\n//40\nval x = sc.parallelize(Array(('C',3),('A',1),('B',2)))\nx.values.collect\n","dateUpdated":"2018-03-22T06:31:09+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"x: org.apache.spark.rdd.RDD[(Char, Int)] = ParallelCollectionRDD[216] at parallelize at <console>:28\nres87: Array[Int] = Array(3, 1, 2)\n"}]},"apps":[],"jobName":"paragraph_1521699681276_-1391425515","id":"20180318-234252_225719704","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16108"},{"text":"%pyspark\n#40\n# values\nx = sc.parallelize([('C',3),('A',1),('B',2)])\ny = x.values()\nprint(y.collect())\n","dateUpdated":"2018-03-22T06:31:09+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[3, 1, 2]\n"}]},"apps":[],"jobName":"paragraph_1521699681276_-1391425515","id":"20180318-234314_423522842","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16109"},{"text":"%md\n### reduceByKey(func, numPartitions=None, partitionFunc=<function portable_hash at 0x7f51f1ac0668>)\n","dateUpdated":"2018-03-22T06:31:10+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>reduceByKey(func, numPartitions=None, partitionFunc=<function portable_hash at 0x7f51f1ac0668>)</h3>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681276_-1391425515","id":"20180320-234337_1684304516","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16110"},{"text":"%md\n![SPARK](https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page44.svg)","dateUpdated":"2018-03-22T06:31:10+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><img src=\"https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page44.svg\" alt=\"SPARK\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681276_-1391425515","id":"20180321-001033_1341963291","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16111"},{"text":"%spark\n//41\nval x = sc.parallelize(Array(('B',1),('B',2),('A',3),('A',4),('A',5)))\nval y = x.reduceByKey((x,y)=> x + y)\ny.collect()","dateUpdated":"2018-03-22T06:31:10+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"x: org.apache.spark.rdd.RDD[(Char, Int)] = ParallelCollectionRDD[218] at parallelize at <console>:28\ny: org.apache.spark.rdd.RDD[(Char, Int)] = ShuffledRDD[225] at reduceByKey at <console>:31\nres89: Array[(Char, Int)] = Array((A,1), (B,2), (C,3))\n"}]},"apps":[],"jobName":"paragraph_1521699681276_-1391425515","id":"20180318-234315_222002562","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16112"},{"text":"%pyspark\n#41\nx = sc.parallelize([('B',1),('B',2),('A',3),('A',4),('A',5)])\ny = x.reduceByKey(lambda agg, obj: agg + obj)\nprint(y.collect())","dateUpdated":"2018-03-22T06:31:10+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[('A', 12), ('B', 3)]\n"}]},"apps":[],"jobName":"paragraph_1521699681276_-1391425515","id":"20180318-234316_1055971401","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16113"},{"text":"%md\n### reduceByKeyLocally(func)\nMerge the values for each key using an associative and commutative reduce function, but return the results immediately to the master as a dictionary\n","dateUpdated":"2018-03-22T06:31:10+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>reduceByKeyLocally(func)</h3>\n<p>Merge the values for each key using an associative and commutative reduce function, but return the results immediately to the master as a dictionary</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681276_-1391425515","id":"20180320-234406_727426834","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16114"},{"text":"%md\n![SPARK](https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page45.svg)","dateUpdated":"2018-03-22T06:31:10+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><img src=\"https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page45.svg\" alt=\"SPARK\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681276_-1391425515","id":"20180321-001042_398302425","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16115"},{"text":"%spark\n//42\nval x = sc.parallelize(Array(('B',1),('B',2),('A',3),('A',4),('A',5)))\nval y = x.reduceByKeyLocally((x,y)=> x + y)\nprintln(y)","dateUpdated":"2018-03-22T06:31:10+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"x: org.apache.spark.rdd.RDD[(Char, Int)] = ParallelCollectionRDD[226] at parallelize at <console>:28\ny: scala.collection.Map[Char,Int] = Map(A -> 12, B -> 3)\nMap(A -> 12, B -> 3)\n"}]},"apps":[],"jobName":"paragraph_1521699681276_-1391425515","id":"20180318-234317_376323777","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16116"},{"text":"%pyspark\n#42\nx = sc.parallelize([('B',1),('B',2),('A',3),('A',4),('A',5)])\ny = x.reduceByKeyLocally(lambda agg, obj: agg + obj)\nprint(y)","dateUpdated":"2018-03-22T06:31:11+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"{'A': 12, 'B': 3}\n"}]},"apps":[],"jobName":"paragraph_1521699681277_-1391810263","id":"20180318-234317_28879114","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16117"},{"text":"%md\n### countByKey()\nCount the number of elements for each key, and return the result to the master as a dictionary.\n","dateUpdated":"2018-03-22T06:31:11+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>countByKey()</h3>\n<p>Count the number of elements for each key, and return the result to the master as a dictionary.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681277_-1391810263","id":"20180320-234424_1128182365","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16118"},{"text":"%md\n![SPARK](https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page46.svg)","dateUpdated":"2018-03-22T06:31:11+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><img src=\"https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page46.svg\" alt=\"SPARK\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681277_-1391810263","id":"20180321-001051_1233977100","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16119"},{"text":"%spark\n//43\nval x = sc.parallelize(Array(('B',1),('B',2),('A',3),('A',4),('A',5)))\nval y = x.countByKey()\nprint(y)\n","dateUpdated":"2018-03-22T06:31:11+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"x: org.apache.spark.rdd.RDD[(Char, Int)] = ParallelCollectionRDD[230] at parallelize at <console>:28\ny: scala.collection.Map[Char,Long] = Map(A -> 3, B -> 2)\nMap(A -> 3, B -> 2)"}]},"apps":[],"jobName":"paragraph_1521699681277_-1391810263","id":"20180318-234316_1347056418","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16120"},{"text":"%pyspark\n#43\nx = sc.parallelize([('B',1),('B',2),('A',3),('A',4),('A',5)])\ny = x.countByKey()\nprint(y)\n","dateUpdated":"2018-03-22T06:31:11+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"defaultdict(<type 'int'>, {'A': 3, 'B': 2})\n"}]},"apps":[],"jobName":"paragraph_1521699681277_-1391810263","id":"20180318-234918_1349187701","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16121"},{"text":"%md\n### join(other, numPartitions=None)\nReturn an RDD containing all pairs of elements with matching keys in self and other.\n\nEach pair of elements will be returned as a (k, (v1, v2)) tuple, where (k, v1) is in self and (k, v2) is in other.\n\nPerforms a hash join across the cluster\n","dateUpdated":"2018-03-22T06:31:11+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>join(other, numPartitions=None)</h3>\n<p>Return an RDD containing all pairs of elements with matching keys in self and other.</p>\n<p>Each pair of elements will be returned as a (k, (v1, v2)) tuple, where (k, v1) is in self and (k, v2) is in other.</p>\n<p>Performs a hash join across the cluster</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681277_-1391810263","id":"20180320-234443_138146915","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16122"},{"text":"%md\n![SPARK](https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page47.svg)\n","dateUpdated":"2018-03-22T06:31:12+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><img src=\"https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page47.svg\" alt=\"SPARK\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681277_-1391810263","id":"20180321-001101_1886119415","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16123"},{"text":"%spark\n//44\nval x = sc.parallelize(Array(('C',4),('B',3),('A',2),('A',1)))\nval y = sc.parallelize(Array(('A',8),('B',7),('A',6),('D',5)))\nval z = x.join(y)\nz.collect\n","dateUpdated":"2018-03-22T06:31:12+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"x: org.apache.spark.rdd.RDD[(Char, Int)] = ParallelCollectionRDD[235] at parallelize at <console>:28\ny: org.apache.spark.rdd.RDD[(Char, Int)] = ParallelCollectionRDD[246] at parallelize at <console>:27\nz: org.apache.spark.rdd.RDD[(Char, (Int, Int))] = MapPartitionsRDD[249] at join at <console>:31\nres95: Array[(Char, (Int, Int))] = Array((A,(2,8)), (A,(2,6)), (A,(1,8)), (A,(1,6)), (B,(3,7)))\n"}]},"apps":[],"jobName":"paragraph_1521699681277_-1391810263","id":"20180318-234918_18601409","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16124"},{"text":"%pyspark\n#44\nx = sc.parallelize([('C',4),('B',3),('A',2),('A',1)])\ny = sc.parallelize([('A',8),('B',7),('A',6),('D',5)])\nz = x.join(y)\nprint(z.collect())\n\n","dateUpdated":"2018-03-22T06:31:12+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[('A', (2, 8)), ('A', (2, 6)), ('A', (1, 8)), ('A', (1, 6)), ('B', (3, 7))]\n"}]},"apps":[],"jobName":"paragraph_1521699681277_-1391810263","id":"20180318-234919_728346281","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16125"},{"text":"%md\n### leftOuterJoin(other, numPartitions=None)\nPerform a left outer join of self and other.\n\nFor each element (k, v) in self, the resulting RDD will either contain all pairs (k, (v, w)) for w in other, or the pair (k, (v, None)) if no elements in other have key k.\n","dateUpdated":"2018-03-22T06:31:12+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>leftOuterJoin(other, numPartitions=None)</h3>\n<p>Perform a left outer join of self and other.</p>\n<p>For each element (k, v) in self, the resulting RDD will either contain all pairs (k, (v, w)) for w in other, or the pair (k, (v, None)) if no elements in other have key k.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681277_-1391810263","id":"20180320-234512_1154274591","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16126"},{"text":"%md\n![SPARK](https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page48.svg)","dateUpdated":"2018-03-22T06:31:12+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><img src=\"https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page48.svg\" alt=\"SPARK\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681277_-1391810263","id":"20180321-001111_986923867","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16127"},{"text":"%spark\n//45\nval x = sc.parallelize(Array(('C',4),('B',3),('A',2),('A',1)))\nval y = sc.parallelize(Array(('A',8),('B',7),('A',6),('D',5)))\nval z = x.leftOuterJoin(y)\nz.collect\n","dateUpdated":"2018-03-22T06:31:12+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"x: org.apache.spark.rdd.RDD[(Char, Int)] = ParallelCollectionRDD[250] at parallelize at <console>:28\ny: org.apache.spark.rdd.RDD[(Char, Int)] = ParallelCollectionRDD[261] at parallelize at <console>:27\nz: org.apache.spark.rdd.RDD[(Char, (Int, Option[Int]))] = MapPartitionsRDD[264] at leftOuterJoin at <console>:31\nres97: Array[(Char, (Int, Option[Int]))] = Array((A,(2,Some(8))), (A,(2,Some(6))), (A,(1,Some(8))), (A,(1,Some(6))), (B,(3,Some(7))), (C,(4,None)))\n"}]},"apps":[],"jobName":"paragraph_1521699681278_-1390656017","id":"20180318-234919_688840868","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16128"},{"text":"%pyspark\n#45\nx = sc.parallelize([('C',4),('B',3),('A',2),('A',1)])\ny = sc.parallelize([('A',8),('B',7),('A',6),('D',5)])\nz = x.leftOuterJoin(y)\nprint(z.collect())\n","dateUpdated":"2018-03-22T06:31:13+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[('A', (2, 8)), ('A', (2, 6)), ('A', (1, 8)), ('A', (1, 6)), ('C', (4, None)), ('B', (3, 7))]\n"}]},"apps":[],"jobName":"paragraph_1521699681278_-1390656017","id":"20180318-234919_2112677505","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16129"},{"text":"%md\n### rightOuterJoin(other, numPartitions=None)\nPerform a right outer join of self and other.\n\nFor each element (k, w) in other, the resulting RDD will either contain all pairs (k, (v, w)) for v in this, or the pair (k, (None, w)) if no elements in self have key k.","dateUpdated":"2018-03-22T06:31:13+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>rightOuterJoin(other, numPartitions=None)</h3>\n<p>Perform a right outer join of self and other.</p>\n<p>For each element (k, w) in other, the resulting RDD will either contain all pairs (k, (v, w)) for v in this, or the pair (k, (None, w)) if no elements in self have key k.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681278_-1390656017","id":"20180320-234544_1321509738","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16130"},{"text":"%md\n![SPARK](https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page49.svg)","dateUpdated":"2018-03-22T06:31:13+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><img src=\"https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page49.svg\" alt=\"SPARK\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681278_-1390656017","id":"20180321-001120_895400418","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16131"},{"text":"%spark\n//46\nval x = sc.parallelize(Array(('C',4),('B',3),('A',2),('A',1)))\nval y = sc.parallelize(Array(('A',8),('B',7),('A',6),('D',5)))\nval z = x.rightOuterJoin(y)\nz.collect\n","dateUpdated":"2018-03-22T06:31:13+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"x: org.apache.spark.rdd.RDD[(Char, Int)] = ParallelCollectionRDD[265] at parallelize at <console>:28\ny: org.apache.spark.rdd.RDD[(Char, Int)] = ParallelCollectionRDD[276] at parallelize at <console>:27\nz: org.apache.spark.rdd.RDD[(Char, (Option[Int], Int))] = MapPartitionsRDD[279] at rightOuterJoin at <console>:31\nres99: Array[(Char, (Option[Int], Int))] = Array((A,(Some(2),8)), (A,(Some(2),6)), (A,(Some(1),8)), (A,(Some(1),6)), (B,(Some(3),7)), (D,(None,5)))\n"}]},"apps":[],"jobName":"paragraph_1521699681278_-1390656017","id":"20180318-234918_608547325","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16132"},{"text":"%pyspark\n#46\nx = sc.parallelize([('C',4),('B',3),('A',2),('A',1)])\ny = sc.parallelize([('A',8),('B',7),('A',6),('D',5)])\nz = x.rightOuterJoin(y)\nprint(z.collect())","dateUpdated":"2018-03-22T06:31:13+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[('A', (2, 8)), ('A', (2, 6)), ('A', (1, 8)), ('A', (1, 6)), ('B', (3, 7)), ('D', (None, 5))]\n"}]},"apps":[],"jobName":"paragraph_1521699681278_-1390656017","id":"20180318-235335_716346887","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16133"},{"text":"%md\n### partitionBy(numPartitions, partitionFunc=<function portable_hash at 0x7f51f1ac0668>)\nReturn a copy of the RDD partitioned using the specified partitioner.\n","dateUpdated":"2018-03-22T06:31:13+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>partitionBy(numPartitions, partitionFunc=<function portable_hash at 0x7f51f1ac0668>)</h3>\n<p>Return a copy of the RDD partitioned using the specified partitioner.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681278_-1390656017","id":"20180320-234600_1410743177","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16134"},{"text":"%md\n![SPARK](https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page50.svg)","dateUpdated":"2018-03-22T06:31:14+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><img src=\"https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page50.svg\" alt=\"SPARK\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681278_-1390656017","id":"20180321-001130_1535839762","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16135"},{"text":"%spark\n//47\nimport org.apache.spark.HashPartitioner\nval x = sc.parallelize(Array(\"hello\",\"hai\",\"there\"))\nval y =x.map(word => (word, 1)).partitionBy(new HashPartitioner(2)) \ny.glom.collect\n\n","dateUpdated":"2018-03-22T06:31:14+0000","config":{"editorSetting":{"language":"scala","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/scala","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"import org.apache.spark.HashPartitioner\nx: org.apache.spark.rdd.RDD[String] = ParallelCollectionRDD[280] at parallelize at <console>:28\ny: org.apache.spark.rdd.RDD[(String, Int)] = ShuffledRDD[289] at partitionBy at <console>:30\nres101: Array[Array[(String, Int)]] = Array(Array((hello,1), (hai,1), (there,1)), Array())\n"}]},"apps":[],"jobName":"paragraph_1521699681278_-1390656017","id":"20180318-235335_307758073","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16136"},{"text":"%pyspark\nx = sc.parallelize([(0,1),(1,2),(2,3)],2)\ny = x.partitionBy(numPartitions = 3, partitionFunc = lambda x: x)  # only key is passed to paritionFunc\nprint(x.glom().collect())\nprint(y.glom().collect())","dateUpdated":"2018-03-22T06:31:14+0000","config":{"editorSetting":{"language":"python","editOnDblClick":false,"completionKey":"TAB"},"colWidth":12,"editorMode":"ace/mode/python","fontSize":9,"editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[[(0, 1)], [(1, 2), (2, 3)]]\n[[(0, 1)], [(1, 2)], [(2, 3)]]\n"}]},"apps":[],"jobName":"paragraph_1521699681279_-1391040766","id":"20180318-235335_2095512744","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16137"},{"text":"%md\n### combineByKey(createCombiner, mergeValue, mergeCombiners, numPartitions=None, partitionFunc=<function portable_hash at 0x7f51f1ac0668>)\nGeneric function to combine the elements for each key using a custom set of aggregation functions.\n\nTurns an RDD[(K, V)] into a result of type RDD[(K, C)], for a “combined type” C.\n\nUsers provide three functions:\n\ncreateCombiner, which turns a V into a C (e.g., creates a one-element list)\nmergeValue, to merge a V into a C (e.g., adds it to the end of a list)\nmergeCombiners, to combine two C’s into a single one (e.g., merges the lists)","dateUpdated":"2018-03-22T06:31:14+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>combineByKey(createCombiner, mergeValue, mergeCombiners, numPartitions=None, partitionFunc=<function portable_hash at 0x7f51f1ac0668>)</h3>\n<p>Generic function to combine the elements for each key using a custom set of aggregation functions.</p>\n<p>Turns an RDD[(K, V)] into a result of type RDD[(K, C)], for a “combined type” C.</p>\n<p>Users provide three functions:</p>\n<p>createCombiner, which turns a V into a C (e.g., creates a one-element list)<br/>mergeValue, to merge a V into a C (e.g., adds it to the end of a list)<br/>mergeCombiners, to combine two C’s into a single one (e.g., merges the lists)</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681279_-1391040766","id":"20180320-234724_1429176768","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16138"},{"text":"%md\n![SPARK](https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page51.svg)","dateUpdated":"2018-03-22T06:31:14+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><img src=\"https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page51.svg\" alt=\"SPARK\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681279_-1391040766","id":"20180321-001143_1387294945","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16139"},{"text":"%pyspark\nx = sc.parallelize([('B',1),('B',2),('A',3),('A',4),('A',5)])\ncreateCombiner = (lambda el: [(el,el**2)]) \nmergeVal = (lambda aggregated, el: aggregated + [(el,el**2)]) # append to aggregated\nmergeComb = (lambda agg1,agg2: agg1 + agg2 )  # append agg1 with agg2\ny = x.combineByKey(createCombiner,mergeVal,mergeComb)\nprint(x.collect())\nprint(y.collect())","dateUpdated":"2018-03-22T06:31:14+0000","config":{"editorSetting":{"language":"python"},"colWidth":12,"editorMode":"ace/mode/python","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[('B', 1), ('B', 2), ('A', 3), ('A', 4), ('A', 5)]\n[('A', [(3, 9), (4, 16), (5, 25)]), ('B', [(1, 1), (2, 4)])]\n"}]},"apps":[],"jobName":"paragraph_1521699681279_-1391040766","id":"20180320-230121_615480978","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16140"},{"text":"%md\n### aggregateByKey(zeroValue, seqFunc, combFunc, numPartitions=None, partitionFunc=<function portable_hash at 0x7f51f1ac0668>)\nAggregate the values of each key, using given combine functions and a neutral “zero value”. This function can return a different result type, U, than the type of the values in this RDD, V. Thus, we need one operation for merging a V into a U and one operation for merging two U’s, The former operation is used for merging values within a partition, and the latter is used for merging values between partitions. To avoid memory allocation, both of these functions are allowed to modify and return their first argument instead of creating a new U.\n","dateUpdated":"2018-03-22T06:31:15+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>aggregateByKey(zeroValue, seqFunc, combFunc, numPartitions=None, partitionFunc=<function portable_hash at 0x7f51f1ac0668>)</h3>\n<p>Aggregate the values of each key, using given combine functions and a neutral “zero value”. This function can return a different result type, U, than the type of the values in this RDD, V. Thus, we need one operation for merging a V into a U and one operation for merging two U’s, The former operation is used for merging values within a partition, and the latter is used for merging values between partitions. To avoid memory allocation, both of these functions are allowed to modify and return their first argument instead of creating a new U.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681279_-1391040766","id":"20180320-234816_774410427","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16141"},{"text":"%md\n![SPARK](https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page52.svg)","dateUpdated":"2018-03-22T06:31:15+0000","config":{"tableHide":true,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><img src=\"https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page52.svg\" alt=\"SPARK\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681279_-1391040766","id":"20180321-001153_862797902","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16142"},{"text":"%pyspark\nx = sc.parallelize([('B',1),('B',2),('A',3),('A',4),('A',5)])\nzeroValue = [] # empty list is 'zero value' for append operation\nmergeVal = (lambda aggregated, el: aggregated + [(el,el**2)])\nmergeComb = (lambda agg1,agg2: agg1 + agg2 )\ny = x.aggregateByKey(zeroValue,mergeVal,mergeComb)\nprint(x.collect())\nprint(y.collect())","dateUpdated":"2018-03-22T06:31:15+0000","config":{"editorSetting":{"language":"python"},"colWidth":12,"editorMode":"ace/mode/python","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[('B', 1), ('B', 2), ('A', 3), ('A', 4), ('A', 5)]\n[('A', [(3, 9), (4, 16), (5, 25)]), ('B', [(1, 1), (2, 4)])]\n"}]},"apps":[],"jobName":"paragraph_1521699681279_-1391040766","id":"20180320-230122_1251221487","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16143"},{"text":"%md\n### foldByKey(zeroValue, func, numPartitions=None, partitionFunc=<function portable_hash at 0x7f51f1ac0668>)\nMerge the values for each key using an associative function “func” and a neutral “zeroValue” which may be added to the result an arbitrary number of times, and must not change the result (e.g., 0 for addition, or 1 for multiplication.).\n","dateUpdated":"2018-03-22T06:31:15+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>foldByKey(zeroValue, func, numPartitions=None, partitionFunc=<function portable_hash at 0x7f51f1ac0668>)</h3>\n<p>Merge the values for each key using an associative function “func” and a neutral “zeroValue” which may be added to the result an arbitrary number of times, and must not change the result (e.g., 0 for addition, or 1 for multiplication.).</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681279_-1391040766","id":"20180320-234841_1611009385","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16144"},{"text":"%md\n![SPARK](https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page53.svg)","dateUpdated":"2018-03-22T06:31:15+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><img src=\"https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page53.svg\" alt=\"SPARK\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681279_-1391040766","id":"20180321-001232_730936320","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16145"},{"text":"%pyspark\nx = sc.parallelize([('B',1),('B',2),('A',3),('A',4),('A',5)])\nzeroValue = 1 # one is 'zero value' for multiplication\ny = x.foldByKey(zeroValue,lambda agg,x: agg*x )  # computes cumulative product within each key\nprint(x.collect())\nprint(y.collect())","dateUpdated":"2018-03-22T06:31:15+0000","config":{"editorSetting":{"language":"python"},"colWidth":12,"editorMode":"ace/mode/python","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[('B', 1), ('B', 2), ('A', 3), ('A', 4), ('A', 5)]\n[('A', 60), ('B', 2)]\n"}]},"apps":[],"jobName":"paragraph_1521699681279_-1391040766","id":"20180320-230124_910322979","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16146"},{"text":"%md\n### groupByKey(numPartitions=None, partitionFunc=<function portable_hash at 0x7f51f1ac0668>)\nGroup the values for each key in the RDD into a single sequence. Hash-partitions the resulting RDD with numPartitions partitions.","dateUpdated":"2018-03-22T06:31:16+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>groupByKey(numPartitions=None, partitionFunc=<function portable_hash at 0x7f51f1ac0668>)</h3>\n<p>Group the values for each key in the RDD into a single sequence. Hash-partitions the resulting RDD with numPartitions partitions.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681280_-1700763630","id":"20180320-234859_878096040","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16147"},{"text":"%md\n![SPARK](https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page54.svg)","dateUpdated":"2018-03-22T06:31:16+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><img src=\"https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page54.svg\" alt=\"SPARK\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681280_-1700763630","id":"20180321-001242_1120191628","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16148"},{"text":"%pyspark\nx = sc.parallelize([('B',5),('B',4),('A',3),('A',2),('A',1)])\ny = x.groupByKey()\nprint(x.collect())\nprint([(j[0],[i for i in j[1]]) for j in y.collect()])","dateUpdated":"2018-03-22T06:31:16+0000","config":{"editorSetting":{"language":"python"},"colWidth":12,"editorMode":"ace/mode/python","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[('B', 5), ('B', 4), ('A', 3), ('A', 2), ('A', 1)]\n[('A', [3, 2, 1]), ('B', [5, 4])]\n"}]},"apps":[],"jobName":"paragraph_1521699681280_-1700763630","id":"20180320-230126_467867514","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16149"},{"text":"%md\n### flatMapValues(f)\nPass each value in the key-value pair RDD through a flatMap function without changing the keys; this also retains the original RDD’s partitioning\n","dateUpdated":"2018-03-22T06:31:16+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>flatMapValues(f)</h3>\n<p>Pass each value in the key-value pair RDD through a flatMap function without changing the keys; this also retains the original RDD’s partitioning</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681280_-1700763630","id":"20180320-234919_1370485439","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16150"},{"text":"%md\n![SPARK](https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page55.svg)","dateUpdated":"2018-03-22T06:31:16+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><img src=\"https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page55.svg\" alt=\"SPARK\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681280_-1700763630","id":"20180321-001252_618942205","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16151"},{"text":"%pyspark\nx = sc.parallelize([('A',(1,2,3)),('B',(4,5))])\ny = x.flatMapValues(lambda x: [i**2 for i in x]) # function is applied to entire value, then result is flattened\nprint(x.collect())\nprint(y.collect())","dateUpdated":"2018-03-22T06:31:16+0000","config":{"editorSetting":{"language":"python"},"colWidth":12,"editorMode":"ace/mode/python","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[('A', (1, 2, 3)), ('B', (4, 5))]\n[('A', 1), ('A', 4), ('A', 9), ('B', 16), ('B', 25)]\n"}]},"apps":[],"jobName":"paragraph_1521699681280_-1700763630","id":"20180320-230125_277615056","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16152"},{"text":"%md\n### mapValues(f)\nPass each value in the key-value pair RDD through a map function without changing the keys; this also retains the original RDD’s partitioning.\n","dateUpdated":"2018-03-22T06:31:17+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>mapValues(f)</h3>\n<p>Pass each value in the key-value pair RDD through a map function without changing the keys; this also retains the original RDD’s partitioning.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681280_-1700763630","id":"20180320-234940_428837102","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16153"},{"text":"%md\n![SPARK](https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page56.svg)\n","dateUpdated":"2018-03-22T06:31:17+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><img src=\"https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page56.svg\" alt=\"SPARK\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681280_-1700763630","id":"20180321-001301_391998385","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16154"},{"text":"%pyspark\nx = sc.parallelize([('A',(1,2,3)),('B',(4,5))])\ny = x.mapValues(lambda x: [i**2 for i in x]) # function is applied to entire value\nprint(x.collect())\nprint(y.collect())","dateUpdated":"2018-03-22T06:31:17+0000","config":{"editorSetting":{"language":"python"},"colWidth":12,"editorMode":"ace/mode/python","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[('A', (1, 2, 3)), ('B', (4, 5))]\n[('A', [1, 4, 9]), ('B', [16, 25])]\n"}]},"apps":[],"jobName":"paragraph_1521699681280_-1700763630","id":"20180320-230125_293962001","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16155"},{"text":"%md\n### groupWith(other, *others)\nAlias for cogroup but with support for multiple RDDs.\n\n\n","dateUpdated":"2018-03-22T06:31:17+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>groupWith(other, *others)<br/>Alias for cogroup but with support for multiple RDDs.</h3>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681280_-1700763630","id":"20180320-235010_1120484541","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16156"},{"text":"%md\n![SPARK](https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page57.svg)","dateUpdated":"2018-03-22T06:31:17+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><img src=\"https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page57.svg\" alt=\"SPARK\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681281_-1701148379","id":"20180321-001311_165268956","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16157"},{"text":"%pyspark\nx = sc.parallelize([('C',4),('B',(3,3)),('A',2),('A',(1,1))])\ny = sc.parallelize([('B',(7,7)),('A',6),('D',(5,5))])\nz = sc.parallelize([('D',9),('B',(8,8))])\na = x.groupWith(y,z)\nprint(x.collect())\nprint(y.collect())\nprint(z.collect())\nprint(\"Result:\")\nfor key,val in list(a.collect()): \n    print(key, [list(i) for i in val])","dateUpdated":"2018-03-22T06:31:17+0000","config":{"editorSetting":{"language":"python"},"colWidth":12,"editorMode":"ace/mode/python","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[('C', 4), ('B', (3, 3)), ('A', 2), ('A', (1, 1))]\n[('B', (7, 7)), ('A', 6), ('D', (5, 5))]\n[('D', 9), ('B', (8, 8))]\nResult:\n('C', [[4], [], []])\n('A', [[2, (1, 1)], [6], []])\n('D', [[], [(5, 5)], [9]])\n('B', [[(3, 3)], [(7, 7)], [(8, 8)]])\n"}]},"apps":[],"jobName":"paragraph_1521699681281_-1701148379","id":"20180320-230125_759823723","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16158"},{"text":"%md\n### cogroup(other, numPartitions=None)\nFor each key k in self or other, return a resulting RDD that contains a tuple with the list of values for that key in self as well as other.\n","dateUpdated":"2018-03-22T06:31:18+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>cogroup(other, numPartitions=None)</h3>\n<p>For each key k in self or other, return a resulting RDD that contains a tuple with the list of values for that key in self as well as other.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681281_-1701148379","id":"20180320-235031_1891251162","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16159"},{"text":"%md\n![SPARK](https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page58.svg)","dateUpdated":"2018-03-22T06:31:18+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><img src=\"https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page58.svg\" alt=\"SPARK\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681281_-1701148379","id":"20180321-001320_1923204323","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16160"},{"text":"%pyspark\nx = sc.parallelize([('C',4),('B',(3,3)),('A',2),('A',(1,1))])\ny = sc.parallelize([('A',8),('B',7),('A',6),('D',(5,5))])\nz = x.cogroup(y)\nprint(x.collect())\nprint(y.collect())\nfor key,val in list(z.collect()):\n    print(key, [list(i) for i in val])","dateUpdated":"2018-03-22T06:31:18+0000","config":{"editorSetting":{"language":"python"},"colWidth":12,"editorMode":"ace/mode/python","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[('C', 4), ('B', (3, 3)), ('A', 2), ('A', (1, 1))]\n[('A', 8), ('B', 7), ('A', 6), ('D', (5, 5))]\n('A', [[2, (1, 1)], [8, 6]])\n('C', [[4], []])\n('B', [[(3, 3)], [7]])\n('D', [[], [(5, 5)]])\n"}]},"apps":[],"jobName":"paragraph_1521699681281_-1701148379","id":"20180320-230125_150639752","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16161"},{"text":"%md\n### sampleByKey(withReplacement, fractions, seed=None)\nReturn a subset of this RDD sampled by key (via stratified sampling). Create a sample of this RDD using variable sampling rates for different keys as specified by fractions, a key to sampling rate map.","dateUpdated":"2018-03-22T06:31:18+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>sampleByKey(withReplacement, fractions, seed=None)</h3>\n<p>Return a subset of this RDD sampled by key (via stratified sampling). Create a sample of this RDD using variable sampling rates for different keys as specified by fractions, a key to sampling rate map.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681281_-1701148379","id":"20180320-235057_905599837","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16162"},{"text":"%md\n![SPARK](https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page59.svg)","dateUpdated":"2018-03-22T06:31:18+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><img src=\"https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page59.svg\" alt=\"SPARK\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681281_-1701148379","id":"20180321-001329_1986249855","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16163"},{"text":"%pyspark\nx = sc.parallelize([('A',1),('B',2),('C',3),('B',4),('A',5)])\ny = x.sampleByKey(withReplacement=False, fractions={'A':0.5, 'B':1, 'C':0.2})\nprint(x.collect())\nprint(y.collect())","dateUpdated":"2018-03-22T06:31:18+0000","config":{"editorSetting":{"language":"python"},"colWidth":12,"editorMode":"ace/mode/python","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[('A', 1), ('B', 2), ('C', 3), ('B', 4), ('A', 5)]\n[('B', 2), ('B', 4), ('A', 5)]\n"}]},"apps":[],"jobName":"paragraph_1521699681281_-1701148379","id":"20180320-230124_1763392734","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16164"},{"text":"%md\n### subtractByKey(other, numPartitions=None)\nReturn each (key, value) pair in self that has no pair with matching key in other.\n","dateUpdated":"2018-03-22T06:31:19+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>subtractByKey(other, numPartitions=None)</h3>\n<p>Return each (key, value) pair in self that has no pair with matching key in other.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681281_-1701148379","id":"20180320-235119_729852341","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16165"},{"text":"%md\n![SPARK](https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page60.svg)","dateUpdated":"2018-03-22T06:31:19+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><img src=\"https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page60.svg\" alt=\"SPARK\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681281_-1701148379","id":"20180321-001338_2009853814","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16166"},{"text":"%pyspark\nx = sc.parallelize([('C',1),('B',2),('A',3),('A',4)])\ny = sc.parallelize([('A',5),('D',6),('A',7),('D',8)])\nz = x.subtractByKey(y)\nprint(x.collect())\nprint(y.collect())\nprint(z.collect())","dateUpdated":"2018-03-22T06:31:19+0000","config":{"editorSetting":{"language":"python"},"colWidth":12,"editorMode":"ace/mode/python","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[('C', 1), ('B', 2), ('A', 3), ('A', 4)]\n[('A', 5), ('D', 6), ('A', 7), ('D', 8)]\n[('C', 1), ('B', 2)]\n"}]},"apps":[],"jobName":"paragraph_1521699681282_-1699994132","id":"20180320-230123_1734640186","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16167"},{"text":"%md\n### subtract(other, numPartitions=None)\nReturn each value in self that is not contained in other.\n","dateUpdated":"2018-03-22T06:31:19+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>subtract(other, numPartitions=None)</h3>\n<p>Return each value in self that is not contained in other.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681282_-1699994132","id":"20180320-235137_1879842555","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16168"},{"text":"%md\n![SPARK](https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page61.svg)","dateUpdated":"2018-03-22T06:31:19+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><img src=\"https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page61.svg\" alt=\"SPARK\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681282_-1699994132","id":"20180321-001348_2060596758","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16169"},{"text":"%pyspark\nx = sc.parallelize([('C',4),('B',3),('A',2),('A',1)])\ny = sc.parallelize([('C',8),('A',2),('D',1)])\nz = x.subtract(y)\nprint(x.collect())\nprint(y.collect())\nprint(z.collect())","dateUpdated":"2018-03-22T06:31:19+0000","config":{"editorSetting":{"language":"python"},"colWidth":12,"editorMode":"ace/mode/python","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[('C', 4), ('B', 3), ('A', 2), ('A', 1)]\n[('C', 8), ('A', 2), ('D', 1)]\n[('B', 3), ('A', 1), ('C', 4)]\n"}]},"apps":[],"jobName":"paragraph_1521699681282_-1699994132","id":"20180320-230123_1089960224","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16170"},{"text":"%md\n### keyBy(f)\nCreates tuples of the elements in this RDD by applying f.\n","dateUpdated":"2018-03-22T06:31:20+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>keyBy(f)</h3>\n<p>Creates tuples of the elements in this RDD by applying f.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681282_-1699994132","id":"20180320-235153_1065664816","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16171"},{"text":"%md\n![SPARK](https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page62.svg)","dateUpdated":"2018-03-22T06:31:20+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><img src=\"https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page62.svg\" alt=\"SPARK\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681282_-1699994132","id":"20180321-001358_614508277","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16172"},{"text":"%pyspark\nx = sc.parallelize([1,2,3])\ny = x.keyBy(lambda x: x**2)\nprint(x.collect())\nprint(y.collect())","dateUpdated":"2018-03-22T06:31:20+0000","config":{"editorSetting":{"language":"python"},"colWidth":12,"editorMode":"ace/mode/python","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[1, 2, 3]\n[(1, 1), (4, 2), (9, 3)]\n"}]},"apps":[],"jobName":"paragraph_1521699681282_-1699994132","id":"20180320-230123_1762680220","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16173"},{"text":"%md\n### repartition(numPartitions)\nReturn a new RDD that has exactly numPartitions partitions.\n\nCan increase or decrease the level of parallelism in this RDD. Internally, this uses a shuffle to redistribute data. If you are decreasing the number of partitions in this RDD, consider using coalesce, which can avoid performing a shuffle.","dateUpdated":"2018-03-22T06:31:20+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>repartition(numPartitions)</h3>\n<p>Return a new RDD that has exactly numPartitions partitions.</p>\n<p>Can increase or decrease the level of parallelism in this RDD. Internally, this uses a shuffle to redistribute data. If you are decreasing the number of partitions in this RDD, consider using coalesce, which can avoid performing a shuffle.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681282_-1699994132","id":"20180320-235217_240894364","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16174"},{"text":"%md\n![SPARK](https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page63.svg)","dateUpdated":"2018-03-22T06:31:20+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><img src=\"https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page63.svg\" alt=\"SPARK\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681282_-1699994132","id":"20180321-001408_786924477","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16175"},{"text":"%pyspark\nx = sc.parallelize([1,2,3,4,5],2)\ny = x.repartition(numPartitions=3)\nprint(x.glom().collect())\nprint(y.glom().collect())","dateUpdated":"2018-03-22T06:31:20+0000","config":{"editorSetting":{"language":"python"},"colWidth":12,"editorMode":"ace/mode/python","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[[1, 2], [3, 4, 5]]\n[[], [1, 2, 3, 4, 5], []]\n"}]},"apps":[],"jobName":"paragraph_1521699681283_-1700378881","id":"20180320-230123_1981127518","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16176"},{"text":"%md\n### coalesce(numPartitions, shuffle=False)\nReturn a new RDD that is reduced into numPartitions partitions.\n","dateUpdated":"2018-03-22T06:31:21+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>coalesce(numPartitions, shuffle=False)</h3>\n<p>Return a new RDD that is reduced into numPartitions partitions.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681283_-1700378881","id":"20180320-235257_1340812644","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16177"},{"text":"%md\n![SPARK](https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page64.svg)","dateUpdated":"2018-03-22T06:31:21+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><img src=\"https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page64.svg\" alt=\"SPARK\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681283_-1700378881","id":"20180321-001417_1497246589","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16178"},{"text":"%pyspark\nx = sc.parallelize([1,2,3,4,5],2)\ny = x.coalesce(numPartitions=1)\nprint(x.glom().collect())\nprint(y.glom().collect())","dateUpdated":"2018-03-22T06:31:21+0000","config":{"editorSetting":{"language":"python"},"colWidth":12,"editorMode":"ace/mode/python","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[[1, 2], [3, 4, 5]]\n[[1, 2, 3, 4, 5]]\n"}]},"apps":[],"jobName":"paragraph_1521699681283_-1700378881","id":"20180320-230122_2032989068","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16179"},{"text":"%md\n### zip(other)\nZips this RDD with another one, returning key-value pairs with the first element in each RDD second element in each RDD, etc. Assumes that the two RDDs have the same number of partitions and the same number of elements in each partition (e.g. one was made through a map on the other).\n","dateUpdated":"2018-03-22T06:31:21+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>zip(other)</h3>\n<p>Zips this RDD with another one, returning key-value pairs with the first element in each RDD second element in each RDD, etc. Assumes that the two RDDs have the same number of partitions and the same number of elements in each partition (e.g. one was made through a map on the other).</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681283_-1700378881","id":"20180320-235316_1859688385","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16180"},{"text":"%md\n![SPARK](https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page65.svg)","dateUpdated":"2018-03-22T06:31:21+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1521699681283_-1700378881","id":"20180321-001427_1714234858","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16181"},{"text":"%pyspark\nx = sc.parallelize(['B','A','A'])\ny = x.map(lambda x: ord(x))  # zip expects x and y to have same #partitions and #elements/partition\nz = x.zip(y)\nprint(x.collect())\nprint(y.collect())\nprint(z.collect())","dateUpdated":"2018-03-22T06:31:21+0000","config":{"editorSetting":{"language":"python"},"colWidth":12,"editorMode":"ace/mode/python","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"['B', 'A', 'A']\n[66, 65, 65]\n[('B', 66), ('A', 65), ('A', 65)]\n"}]},"apps":[],"jobName":"paragraph_1521699681283_-1700378881","id":"20180320-230122_218882449","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16182"},{"text":"%md\n### zipWithIndex()\nZips this RDD with its element indices.\n\nThe ordering is first based on the partition index and then the ordering of items within each partition. So the first item in the first partition gets index 0, and the last item in the last partition receives the largest index.\n\nThis method needs to trigger a spark job when this RDD contains more than one partitions.","dateUpdated":"2018-03-22T06:31:21+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>zipWithIndex()</h3>\n<p>Zips this RDD with its element indices.</p>\n<p>The ordering is first based on the partition index and then the ordering of items within each partition. So the first item in the first partition gets index 0, and the last item in the last partition receives the largest index.</p>\n<p>This method needs to trigger a spark job when this RDD contains more than one partitions.</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681283_-1700378881","id":"20180320-235334_1292648269","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16183"},{"text":"%md\n![SPARK](https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page66.svg)","dateUpdated":"2018-03-22T06:31:22+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><img src=\"https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page66.svg\" alt=\"SPARK\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681283_-1700378881","id":"20180321-001437_1980539771","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16184"},{"text":"%pyspark\nx = sc.parallelize(['B','A','A'],2)\ny = x.zipWithIndex()\nprint(x.glom().collect())\nprint(y.collect())","dateUpdated":"2018-03-22T06:31:22+0000","config":{"editorSetting":{"language":"python"},"colWidth":12,"editorMode":"ace/mode/python","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[['B'], ['A', 'A']]\n[('B', 0), ('A', 1), ('A', 2)]\n"}]},"apps":[],"jobName":"paragraph_1521699681284_-1702302626","id":"20180320-230121_779373676","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16185"},{"text":"%md\n### zipWithUniqueId()\nZips this RDD with generated unique Long ids.\n\nItems in the kth partition will get ids k, n+k, 2*n+k, ..., where n is the number of partitions. So there may exist gaps, but this method won’t trigger a spark job, which is different from zipWithIndex\n","dateUpdated":"2018-03-22T06:31:22+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<h3>zipWithUniqueId()</h3>\n<p>Zips this RDD with generated unique Long ids.</p>\n<p>Items in the kth partition will get ids k, n+k, 2*n+k, &hellip;, where n is the number of partitions. So there may exist gaps, but this method won’t trigger a spark job, which is different from zipWithIndex</p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681284_-1702302626","id":"20180320-235346_438155930","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16186"},{"text":"%md\n![SPARK](https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page67.svg)","dateUpdated":"2018-03-22T06:31:22+0000","config":{"tableHide":false,"editorSetting":{"language":"markdown","editOnDblClick":true},"colWidth":12,"editorMode":"ace/mode/markdown","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"HTML","data":"<div class=\"markdown-body\">\n<p><img src=\"https://s3.amazonaws.com/yb-spark-training/spark-images/pyspark-page67.svg\" alt=\"SPARK\" /></p>\n</div>"}]},"apps":[],"jobName":"paragraph_1521699681284_-1702302626","id":"20180321-001447_1153835140","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16187"},{"text":"%pyspark\nx = sc.parallelize(['B','A','A'],2)\ny = x.zipWithUniqueId()\nprint(x.glom().collect())\nprint(y.collect())","dateUpdated":"2018-03-22T06:31:22+0000","config":{"editorSetting":{"language":"python"},"colWidth":12,"editorMode":"ace/mode/python","editorHide":false,"results":{},"enabled":true},"settings":{"params":{},"forms":{}},"results":{"code":"SUCCESS","msg":[{"type":"TEXT","data":"[['B'], ['A', 'A']]\n[('B', 0), ('A', 1), ('A', 3)]\n"}]},"apps":[],"jobName":"paragraph_1521699681284_-1702302626","id":"20180320-230429_2076101002","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16188"},{"text":"%pyspark\n","dateUpdated":"2018-03-22T06:31:22+0000","config":{"colWidth":12,"editorMode":"ace/mode/python","results":{},"enabled":true,"editorSetting":{"language":"python"},"editorHide":false},"settings":{"params":{},"forms":{}},"apps":[],"jobName":"paragraph_1521699681284_-1702302626","id":"20180321-214428_1760743098","dateCreated":"2018-03-22T06:21:21+0000","status":"READY","errorMessage":"","progressUpdateIntervalMs":500,"$$hashKey":"object:16189"}],"name":"Day1_Session2/SPARK_RDD","id":"2D8YC98QU","angularObjects":{"2DB3P8PY3:admin:":[],"2DB8QWR55:shared_process":[],"2DBBZ71CA:shared_process":[],"2D86ZKS6A:shared_process":[],"2DB1EA7GQ:shared_process":[],"2DB8HDXX9:shared_process":[],"2D9SGTKDN:shared_process":[]},"config":{"looknfeel":"default","personalizedMode":"false"},"info":{}}